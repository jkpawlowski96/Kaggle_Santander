{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load file and libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "#import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Loading files\"\"\"\n",
    "train=pd.read_csv('./input/train.csv')\n",
    "test=pd.read_csv('./input/test.csv')\n",
    "\n",
    "\"\"\"Dealing with labels\"\"\"\n",
    "submission=pd.DataFrame()\n",
    "y_train=train['target']\n",
    "submission['ID_code']=test['ID_code']\n",
    "train.drop(columns=['target','ID_code'],inplace=True)\n",
    "test.drop(columns=['ID_code'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7   var_8  \\\n",
       "0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266 -4.9200   \n",
       "1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338  3.1468   \n",
       "2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155 -4.9193   \n",
       "3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250 -5.8609   \n",
       "4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514  6.2654   \n",
       "\n",
       "    var_9   ...     var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  5.7470   ...      4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  8.0851   ...      7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  5.9525   ...      2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  8.2450   ...      4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  7.6784   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>8.8100</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>5.9739</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>8.3442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>7.4578</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>7.1437</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0    var_1    var_2   var_3    var_4   var_5   var_6    var_7  \\\n",
       "0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493  18.2675   \n",
       "1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196  18.6316   \n",
       "2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950  20.2537   \n",
       "3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397  20.5660   \n",
       "4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595  10.6048   \n",
       "\n",
       "    var_8   var_9   ...     var_190  var_191  var_192  var_193  var_194  \\\n",
       "0  2.1337  8.8100   ...     -2.1556  11.8495  -1.4300   2.4508  13.7112   \n",
       "1 -4.4131  5.9739   ...     10.6165   8.8349   0.9403  10.1282  15.5765   \n",
       "2  1.5233  8.3442   ...     -0.7484  10.9935   1.9803   2.1800  12.9813   \n",
       "3  3.3755  7.4578   ...      9.5702   9.0766   1.6580   3.5813  15.1874   \n",
       "4  2.9890  7.1437   ...      4.2259   9.1723   1.2835   3.3778  19.5542   \n",
       "\n",
       "   var_195  var_196  var_197  var_198  var_199  \n",
       "0   2.4669   4.3654  10.7200  15.4722  -8.7197  \n",
       "1   0.4773  -1.4852   9.8714  19.1293 -20.9760  \n",
       "2   2.1281  -7.1086   7.0618  19.8956 -23.1794  \n",
       "3   3.1656   3.9567   9.2295  13.0168  -4.2108  \n",
       "4  -0.2860  -5.1612   7.2882  13.9260  -9.1846  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_float(data, usecols):\n",
    "    for col in usecols:\n",
    "        try:\n",
    "            data[col] = data[col].astype(np.float32)\n",
    "        except:\n",
    "            print(f'{col} cannot be casted to number')\n",
    "    return data\n",
    "\n",
    "#'''\n",
    "columns=train.columns\n",
    "#train = convert_to_float(train, train.columns)\n",
    "#test = convert_to_float(test, test.columns)\n",
    "\n",
    "train = train.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "train = min_max_scaler.fit_transform(train)\n",
    "test=test.values\n",
    "test =  min_max_scaler.transform(test)\n",
    "train = pd.DataFrame(train)\n",
    "test = pd.DataFrame(test)\n",
    "train.columns=columns\n",
    "test.columns=columns\n",
    "\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.427853</td>\n",
       "      <td>0.324824</td>\n",
       "      <td>0.568059</td>\n",
       "      <td>0.388041</td>\n",
       "      <td>0.550670</td>\n",
       "      <td>0.467321</td>\n",
       "      <td>0.454298</td>\n",
       "      <td>0.594255</td>\n",
       "      <td>0.270395</td>\n",
       "      <td>0.247420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569515</td>\n",
       "      <td>0.342943</td>\n",
       "      <td>0.568958</td>\n",
       "      <td>0.448173</td>\n",
       "      <td>0.510975</td>\n",
       "      <td>0.300318</td>\n",
       "      <td>0.678981</td>\n",
       "      <td>0.430958</td>\n",
       "      <td>0.327658</td>\n",
       "      <td>0.560645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.557212</td>\n",
       "      <td>0.428639</td>\n",
       "      <td>0.681235</td>\n",
       "      <td>0.410417</td>\n",
       "      <td>0.628408</td>\n",
       "      <td>0.795072</td>\n",
       "      <td>0.536604</td>\n",
       "      <td>0.500584</td>\n",
       "      <td>0.660911</td>\n",
       "      <td>0.573056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668079</td>\n",
       "      <td>0.536531</td>\n",
       "      <td>0.523717</td>\n",
       "      <td>0.756190</td>\n",
       "      <td>0.350211</td>\n",
       "      <td>0.765154</td>\n",
       "      <td>0.686614</td>\n",
       "      <td>0.468277</td>\n",
       "      <td>0.609546</td>\n",
       "      <td>0.605827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.411969</td>\n",
       "      <td>0.483777</td>\n",
       "      <td>0.578061</td>\n",
       "      <td>0.599690</td>\n",
       "      <td>0.474941</td>\n",
       "      <td>0.471329</td>\n",
       "      <td>0.753295</td>\n",
       "      <td>0.414724</td>\n",
       "      <td>0.270429</td>\n",
       "      <td>0.276041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522496</td>\n",
       "      <td>0.643141</td>\n",
       "      <td>0.448960</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.671183</td>\n",
       "      <td>0.881350</td>\n",
       "      <td>0.236337</td>\n",
       "      <td>0.381950</td>\n",
       "      <td>0.425833</td>\n",
       "      <td>0.582736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.535099</td>\n",
       "      <td>0.507140</td>\n",
       "      <td>0.396562</td>\n",
       "      <td>0.546993</td>\n",
       "      <td>0.647586</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.572995</td>\n",
       "      <td>0.428577</td>\n",
       "      <td>0.224846</td>\n",
       "      <td>0.595326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570474</td>\n",
       "      <td>0.383085</td>\n",
       "      <td>0.370986</td>\n",
       "      <td>0.439205</td>\n",
       "      <td>0.745555</td>\n",
       "      <td>0.418549</td>\n",
       "      <td>0.346810</td>\n",
       "      <td>0.717176</td>\n",
       "      <td>0.590016</td>\n",
       "      <td>0.443232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.473637</td>\n",
       "      <td>0.533434</td>\n",
       "      <td>0.624133</td>\n",
       "      <td>0.504796</td>\n",
       "      <td>0.621079</td>\n",
       "      <td>0.702836</td>\n",
       "      <td>0.589011</td>\n",
       "      <td>0.622220</td>\n",
       "      <td>0.811883</td>\n",
       "      <td>0.516413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387371</td>\n",
       "      <td>0.629275</td>\n",
       "      <td>0.299888</td>\n",
       "      <td>0.697737</td>\n",
       "      <td>0.238801</td>\n",
       "      <td>0.393218</td>\n",
       "      <td>0.557507</td>\n",
       "      <td>0.586526</td>\n",
       "      <td>0.591416</td>\n",
       "      <td>0.446041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_0     var_1     var_2     var_3     var_4     var_5     var_6  \\\n",
       "0  0.427853  0.324824  0.568059  0.388041  0.550670  0.467321  0.454298   \n",
       "1  0.557212  0.428639  0.681235  0.410417  0.628408  0.795072  0.536604   \n",
       "2  0.411969  0.483777  0.578061  0.599690  0.474941  0.471329  0.753295   \n",
       "3  0.535099  0.507140  0.396562  0.546993  0.647586  0.616822  0.572995   \n",
       "4  0.473637  0.533434  0.624133  0.504796  0.621079  0.702836  0.589011   \n",
       "\n",
       "      var_7     var_8     var_9    ...      var_190   var_191   var_192  \\\n",
       "0  0.594255  0.270395  0.247420    ...     0.569515  0.342943  0.568958   \n",
       "1  0.500584  0.660911  0.573056    ...     0.668079  0.536531  0.523717   \n",
       "2  0.414724  0.270429  0.276041    ...     0.522496  0.643141  0.448960   \n",
       "3  0.428577  0.224846  0.595326    ...     0.570474  0.383085  0.370986   \n",
       "4  0.622220  0.811883  0.516413    ...     0.387371  0.629275  0.299888   \n",
       "\n",
       "    var_193   var_194   var_195   var_196   var_197   var_198   var_199  \n",
       "0  0.448173  0.510975  0.300318  0.678981  0.430958  0.327658  0.560645  \n",
       "1  0.756190  0.350211  0.765154  0.686614  0.468277  0.609546  0.605827  \n",
       "2  0.448000  0.671183  0.881350  0.236337  0.381950  0.425833  0.582736  \n",
       "3  0.439205  0.745555  0.418549  0.346810  0.717176  0.590016  0.443232  \n",
       "4  0.697737  0.238801  0.393218  0.557507  0.586526  0.591416  0.446041  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.535360</td>\n",
       "      <td>0.897837</td>\n",
       "      <td>0.628717</td>\n",
       "      <td>0.715833</td>\n",
       "      <td>0.548256</td>\n",
       "      <td>0.605894</td>\n",
       "      <td>0.574061</td>\n",
       "      <td>0.578182</td>\n",
       "      <td>0.611866</td>\n",
       "      <td>0.674016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366928</td>\n",
       "      <td>0.749230</td>\n",
       "      <td>0.195180</td>\n",
       "      <td>0.473444</td>\n",
       "      <td>0.260824</td>\n",
       "      <td>0.810571</td>\n",
       "      <td>0.570992</td>\n",
       "      <td>0.788006</td>\n",
       "      <td>0.463751</td>\n",
       "      <td>0.447387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.408005</td>\n",
       "      <td>0.641132</td>\n",
       "      <td>0.533050</td>\n",
       "      <td>0.395056</td>\n",
       "      <td>0.355501</td>\n",
       "      <td>0.573148</td>\n",
       "      <td>0.601977</td>\n",
       "      <td>0.594479</td>\n",
       "      <td>0.294934</td>\n",
       "      <td>0.279021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759502</td>\n",
       "      <td>0.593904</td>\n",
       "      <td>0.389199</td>\n",
       "      <td>0.728803</td>\n",
       "      <td>0.357802</td>\n",
       "      <td>0.601884</td>\n",
       "      <td>0.391146</td>\n",
       "      <td>0.647505</td>\n",
       "      <td>0.648642</td>\n",
       "      <td>0.265418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.254905</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.535820</td>\n",
       "      <td>0.447373</td>\n",
       "      <td>0.850517</td>\n",
       "      <td>0.417628</td>\n",
       "      <td>0.667081</td>\n",
       "      <td>0.582317</td>\n",
       "      <td>0.609142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410181</td>\n",
       "      <td>0.705125</td>\n",
       "      <td>0.474327</td>\n",
       "      <td>0.464437</td>\n",
       "      <td>0.222877</td>\n",
       "      <td>0.775034</td>\n",
       "      <td>0.218283</td>\n",
       "      <td>0.182324</td>\n",
       "      <td>0.687383</td>\n",
       "      <td>0.232704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.408357</td>\n",
       "      <td>0.539775</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.500064</td>\n",
       "      <td>0.325182</td>\n",
       "      <td>0.717406</td>\n",
       "      <td>0.424956</td>\n",
       "      <td>0.681060</td>\n",
       "      <td>0.671982</td>\n",
       "      <td>0.485690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727342</td>\n",
       "      <td>0.606357</td>\n",
       "      <td>0.447945</td>\n",
       "      <td>0.511046</td>\n",
       "      <td>0.337572</td>\n",
       "      <td>0.883857</td>\n",
       "      <td>0.558429</td>\n",
       "      <td>0.541227</td>\n",
       "      <td>0.339614</td>\n",
       "      <td>0.514331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.567520</td>\n",
       "      <td>0.586569</td>\n",
       "      <td>0.696941</td>\n",
       "      <td>0.588941</td>\n",
       "      <td>0.347404</td>\n",
       "      <td>0.481345</td>\n",
       "      <td>0.739656</td>\n",
       "      <td>0.235211</td>\n",
       "      <td>0.653272</td>\n",
       "      <td>0.441944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563075</td>\n",
       "      <td>0.611288</td>\n",
       "      <td>0.417291</td>\n",
       "      <td>0.504277</td>\n",
       "      <td>0.564603</td>\n",
       "      <td>0.521822</td>\n",
       "      <td>0.278146</td>\n",
       "      <td>0.219809</td>\n",
       "      <td>0.385580</td>\n",
       "      <td>0.440485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_0     var_1     var_2     var_3     var_4     var_5     var_6  \\\n",
       "0  0.535360  0.897837  0.628717  0.715833  0.548256  0.605894  0.574061   \n",
       "1  0.408005  0.641132  0.533050  0.395056  0.355501  0.573148  0.601977   \n",
       "2  0.254905  0.184314  0.465517  0.535820  0.447373  0.850517  0.417628   \n",
       "3  0.408357  0.539775  0.574667  0.500064  0.325182  0.717406  0.424956   \n",
       "4  0.567520  0.586569  0.696941  0.588941  0.347404  0.481345  0.739656   \n",
       "\n",
       "      var_7     var_8     var_9    ...      var_190   var_191   var_192  \\\n",
       "0  0.578182  0.611866  0.674016    ...     0.366928  0.749230  0.195180   \n",
       "1  0.594479  0.294934  0.279021    ...     0.759502  0.593904  0.389199   \n",
       "2  0.667081  0.582317  0.609142    ...     0.410181  0.705125  0.474327   \n",
       "3  0.681060  0.671982  0.485690    ...     0.727342  0.606357  0.447945   \n",
       "4  0.235211  0.653272  0.441944    ...     0.563075  0.611288  0.417291   \n",
       "\n",
       "    var_193   var_194   var_195   var_196   var_197   var_198   var_199  \n",
       "0  0.473444  0.260824  0.810571  0.570992  0.788006  0.463751  0.447387  \n",
       "1  0.728803  0.357802  0.601884  0.391146  0.647505  0.648642  0.265418  \n",
       "2  0.464437  0.222877  0.775034  0.218283  0.182324  0.687383  0.232704  \n",
       "3  0.511046  0.337572  0.883857  0.558429  0.541227  0.339614  0.514331  \n",
       "4  0.504277  0.564603  0.521822  0.278146  0.219809  0.385580  0.440485  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "clusters=20\n",
    "model = KMeans(n_clusters=clusters)\n",
    "\n",
    "labels_train=model.fit_predict(train)\n",
    "labels_test=model.predict(test)\n",
    "\n",
    "train['Cluster']=labels_train\n",
    "test['Cluster']=labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster nr: 0 test items: 9873 mean: 0.07876370887337986\n",
      "Cluster nr: 1 test items: 10020 mean: 0.0808793868495361\n",
      "Cluster nr: 2 test items: 10158 mean: 0.08546659867414584\n",
      "Cluster nr: 3 test items: 10060 mean: 0.08256695300656898\n",
      "Cluster nr: 4 test items: 10102 mean: 0.07867270578968098\n",
      "Cluster nr: 5 test items: 9573 mean: 0.11195426195426196\n",
      "Cluster nr: 6 test items: 9782 mean: 0.06595201633486472\n",
      "Cluster nr: 7 test items: 10116 mean: 0.08668577641593357\n",
      "Cluster nr: 8 test items: 10274 mean: 0.08894422310756972\n",
      "Cluster nr: 9 test items: 8364 mean: 0.49000108096422007\n",
      "Cluster nr: 10 test items: 9757 mean: 0.08909706996212877\n",
      "Cluster nr: 11 test items: 9902 mean: 0.08043764562860906\n",
      "Cluster nr: 12 test items: 10213 mean: 0.06645219664220368\n",
      "Cluster nr: 13 test items: 10676 mean: 0.07467224016720501\n",
      "Cluster nr: 14 test items: 10171 mean: 0.08006188358151228\n",
      "Cluster nr: 15 test items: 10300 mean: 0.09503643884183573\n",
      "Cluster nr: 16 test items: 10469 mean: 0.06579201234806097\n",
      "Cluster nr: 17 test items: 10043 mean: 0.07961264016309888\n",
      "Cluster nr: 18 test items: 10166 mean: 0.06942421594329547\n",
      "Cluster nr: 19 test items: 9981 mean: 0.09176142030720127\n",
      "-----Test dataset results-----\n",
      "Clusters homogeneity: 0.9013379713188158\n"
     ]
    }
   ],
   "source": [
    "mean_clusters=np.array(range(clusters))\n",
    "mean_train=labels_train\n",
    "mean_test=labels_test\n",
    "\n",
    "#how many rows in test\n",
    "rows=np.shape(test)[0]\n",
    "\n",
    "#score for measure accuracy of clasters\n",
    "score=0\n",
    "\n",
    "for cluster in range(clusters):\n",
    "    #compute the mean (HasDetection) of cluster\n",
    "    #mean =np.mean(Y_test.loc[test['Cluster'] == cluster])  #test measure\n",
    "    mean =np.mean(y_train.loc[train['Cluster'] == cluster]) # train measure\n",
    "    mean_clusters=np.where(mean_clusters==cluster, mean, mean_clusters)\n",
    "    #how many rows cluster has in test \n",
    "    count=test[test['Cluster']==cluster].count()[0]\n",
    "    #score for measure accuracy of clasters\n",
    "    score=score+abs(mean-0.5)*count/rows\n",
    "    print(\"Cluster nr:\",cluster,'test items:',count,'mean:',mean)\n",
    "    mean_train=np.where(mean_train==cluster, mean, mean_train)\n",
    "    mean_test=np.where(mean_test==cluster, mean, mean_test)\n",
    "\n",
    "print('-----Test dataset results-----')    \n",
    "print('Clusters homogeneity:',0.5+score)\n",
    "\n",
    "#train['Cluster_pred']=mean_train\n",
    "#test['Cluster_pred']=mean_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "model = MLPRegressor(hidden_layer_sizes=(200,), \n",
    "                    max_iter=50,\n",
    "                    learning_rate_init=.1,\n",
    "                    early_stopping=True,\n",
    "                    activation = 'relu',\n",
    "                    learning_rate = 'adaptive',\n",
    "                    solver='sgd', \n",
    "                    verbose=True,          \n",
    "                    random_state=32563246)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.26061132\n",
      "Validation score: -0.414730\n",
      "Iteration 2, loss = 0.04050354\n",
      "Validation score: -0.003766\n",
      "Iteration 3, loss = 0.03954241\n",
      "Validation score: -0.005376\n",
      "Iteration 4, loss = 0.03955146\n",
      "Validation score: -0.000092\n",
      "Iteration 5, loss = 0.03953831\n",
      "Validation score: -0.007020\n",
      "Iteration 6, loss = 0.03952916\n",
      "Validation score: -0.004550\n",
      "Iteration 7, loss = 0.03950828\n",
      "Validation score: -0.004090\n",
      "Iteration 8, loss = 0.03949857\n",
      "Validation score: -0.002897\n",
      "Iteration 9, loss = 0.03947220\n",
      "Validation score: -0.004195\n",
      "Iteration 10, loss = 0.03957164\n",
      "Validation score: -0.000187\n",
      "Iteration 11, loss = 0.03950163\n",
      "Validation score: -0.005661\n",
      "Iteration 12, loss = 0.03950849\n",
      "Validation score: -0.010317\n",
      "Iteration 13, loss = 0.03950880\n",
      "Validation score: -0.000188\n",
      "Iteration 14, loss = 0.03950454\n",
      "Validation score: -0.003606\n",
      "Iteration 15, loss = 0.03951304\n",
      "Validation score: -0.001291\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 16, loss = 0.03944831\n",
      "Validation score: -0.004640\n",
      "Iteration 17, loss = 0.03946734\n",
      "Validation score: -0.003073\n",
      "Iteration 18, loss = 0.03947184\n",
      "Validation score: -0.001394\n",
      "Iteration 19, loss = 0.03945320\n",
      "Validation score: -0.001492\n",
      "Iteration 20, loss = 0.03946985\n",
      "Validation score: -0.001615\n",
      "Iteration 21, loss = 0.03946452\n",
      "Validation score: -0.002264\n",
      "Iteration 22, loss = 0.03945999\n",
      "Validation score: -0.004006\n",
      "Iteration 23, loss = 0.03945589\n",
      "Validation score: -0.006067\n",
      "Iteration 24, loss = 0.03947970\n",
      "Validation score: -0.002458\n",
      "Iteration 25, loss = 0.03944893\n",
      "Validation score: -0.000116\n",
      "Iteration 26, loss = 0.03946712\n",
      "Validation score: -0.002978\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 27, loss = 0.03944794\n",
      "Validation score: -0.001576\n",
      "Iteration 28, loss = 0.03944406\n",
      "Validation score: -0.002550\n",
      "Iteration 29, loss = 0.03944865\n",
      "Validation score: -0.002580\n",
      "Iteration 30, loss = 0.03945005\n",
      "Validation score: -0.002709\n",
      "Iteration 31, loss = 0.03945245\n",
      "Validation score: -0.001718\n",
      "Iteration 32, loss = 0.03944795\n",
      "Validation score: -0.001836\n",
      "Iteration 33, loss = 0.03944990\n",
      "Validation score: -0.002691\n",
      "Iteration 34, loss = 0.03944585\n",
      "Validation score: -0.002134\n",
      "Iteration 35, loss = 0.03944973\n",
      "Validation score: -0.002599\n",
      "Iteration 36, loss = 0.03944568\n",
      "Validation score: -0.002340\n",
      "Iteration 37, loss = 0.03944789\n",
      "Validation score: -0.002409\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 38, loss = 0.03944462\n",
      "Validation score: -0.002122\n",
      "Iteration 39, loss = 0.03944458\n",
      "Validation score: -0.002179\n",
      "Iteration 40, loss = 0.03944451\n",
      "Validation score: -0.002312\n",
      "Iteration 41, loss = 0.03944438\n",
      "Validation score: -0.002311\n",
      "Iteration 42, loss = 0.03944491\n",
      "Validation score: -0.002168\n",
      "Iteration 43, loss = 0.03944420\n",
      "Validation score: -0.002286\n",
      "Iteration 44, loss = 0.03944412\n",
      "Validation score: -0.002310\n",
      "Iteration 45, loss = 0.03944383\n",
      "Validation score: -0.002113\n",
      "Iteration 46, loss = 0.03944501\n",
      "Validation score: -0.001976\n",
      "Iteration 47, loss = 0.03944469\n",
      "Validation score: -0.002033\n",
      "Iteration 48, loss = 0.03944415\n",
      "Validation score: -0.002308\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000160\n",
      "Iteration 49, loss = 0.03944403\n",
      "Validation score: -0.002667\n",
      "Iteration 50, loss = 0.03944426\n",
      "Validation score: -0.002589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.59842003\n",
      "Validation score: -0.137297\n",
      "Iteration 2, loss = 0.03877121\n",
      "Validation score: -0.000160\n",
      "Iteration 3, loss = 0.03790206\n",
      "Validation score: -0.000704\n",
      "Iteration 4, loss = 0.03788089\n",
      "Validation score: -0.000254\n",
      "Iteration 5, loss = 0.03784562\n",
      "Validation score: -0.000355\n",
      "Iteration 6, loss = 0.03787915\n",
      "Validation score: -0.001053\n",
      "Iteration 7, loss = 0.03789168\n",
      "Validation score: -0.000472\n",
      "Iteration 8, loss = 0.03784172\n",
      "Validation score: -0.000667\n",
      "Iteration 9, loss = 0.03787951\n",
      "Validation score: -0.000819\n",
      "Iteration 10, loss = 0.03788134\n",
      "Validation score: -0.003558\n",
      "Iteration 11, loss = 0.03789422\n",
      "Validation score: -0.000505\n",
      "Iteration 12, loss = 0.03788066\n",
      "Validation score: -0.001872\n",
      "Iteration 13, loss = 0.03787013\n",
      "Validation score: 0.000149\n",
      "Iteration 14, loss = 0.03788829\n",
      "Validation score: -0.006500\n",
      "Iteration 15, loss = 0.03784251\n",
      "Validation score: -0.000546\n",
      "Iteration 16, loss = 0.03783985\n",
      "Validation score: 0.002179\n",
      "Iteration 17, loss = 0.03772343\n",
      "Validation score: 0.000611\n",
      "Iteration 18, loss = 0.03762722\n",
      "Validation score: 0.009187\n",
      "Iteration 19, loss = 0.03735354\n",
      "Validation score: 0.014786\n",
      "Iteration 20, loss = 0.03700449\n",
      "Validation score: 0.014989\n",
      "Iteration 21, loss = 0.03667630\n",
      "Validation score: 0.032976\n",
      "Iteration 22, loss = 0.03600028\n",
      "Validation score: 0.041818\n",
      "Iteration 23, loss = 0.03542466\n",
      "Validation score: 0.061036\n",
      "Iteration 24, loss = 0.03534570\n",
      "Validation score: 0.051454\n",
      "Iteration 25, loss = 0.03469424\n",
      "Validation score: 0.075571\n",
      "Iteration 26, loss = 0.03439591\n",
      "Validation score: 0.076745\n",
      "Iteration 27, loss = 0.03403646\n",
      "Validation score: 0.061088\n",
      "Iteration 28, loss = 0.03375977\n",
      "Validation score: 0.063640\n",
      "Iteration 29, loss = 0.03368516\n",
      "Validation score: 0.080578\n",
      "Iteration 30, loss = 0.03339859\n",
      "Validation score: 0.079137\n",
      "Iteration 31, loss = 0.03353591\n",
      "Validation score: 0.033139\n",
      "Iteration 32, loss = 0.03292806\n",
      "Validation score: 0.048589\n",
      "Iteration 33, loss = 0.03334709\n",
      "Validation score: 0.047220\n",
      "Iteration 34, loss = 0.03378483\n",
      "Validation score: 0.060714\n",
      "Iteration 35, loss = 0.03362656\n",
      "Validation score: 0.078364\n",
      "Iteration 36, loss = 0.03373426\n",
      "Validation score: -0.008606\n",
      "Iteration 37, loss = 0.03341679\n",
      "Validation score: 0.079912\n",
      "Iteration 38, loss = 0.03323346\n",
      "Validation score: 0.057701\n",
      "Iteration 39, loss = 0.03341005\n",
      "Validation score: 0.084437\n",
      "Iteration 40, loss = 0.03329357\n",
      "Validation score: 0.081221\n",
      "Iteration 41, loss = 0.03330779\n",
      "Validation score: 0.026062\n",
      "Iteration 42, loss = 0.03312271\n",
      "Validation score: 0.080420\n",
      "Iteration 43, loss = 0.03336296\n",
      "Validation score: 0.083597\n",
      "Iteration 44, loss = 0.03323304\n",
      "Validation score: 0.013203\n",
      "Iteration 45, loss = 0.03332145\n",
      "Validation score: 0.062456\n",
      "Iteration 46, loss = 0.03314679\n",
      "Validation score: 0.069835\n",
      "Iteration 47, loss = 0.03342070\n",
      "Validation score: 0.066930\n",
      "Iteration 48, loss = 0.03313319\n",
      "Validation score: 0.083128\n",
      "Iteration 49, loss = 0.03315813\n",
      "Validation score: 0.084426\n",
      "Iteration 50, loss = 0.03293430\n",
      "Validation score: 0.079135\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.020000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.65287594\n",
      "Validation score: -0.301442\n",
      "Iteration 2, loss = 0.04396059\n",
      "Validation score: -0.000252\n",
      "Iteration 3, loss = 0.04325874\n",
      "Validation score: -0.000014\n",
      "Iteration 4, loss = 0.04321615\n",
      "Validation score: -0.002338\n",
      "Iteration 5, loss = 0.04322344\n",
      "Validation score: -0.003770\n",
      "Iteration 6, loss = 0.04318528\n",
      "Validation score: -0.002388\n",
      "Iteration 7, loss = 0.04328940\n",
      "Validation score: -0.005928\n",
      "Iteration 8, loss = 0.04324161\n",
      "Validation score: -0.002677\n",
      "Iteration 9, loss = 0.04318372\n",
      "Validation score: -0.005012\n",
      "Iteration 10, loss = 0.04323917\n",
      "Validation score: -0.003582\n",
      "Iteration 11, loss = 0.04327331\n",
      "Validation score: -0.023762\n",
      "Iteration 12, loss = 0.04331471\n",
      "Validation score: -0.000109\n",
      "Iteration 13, loss = 0.04322329\n",
      "Validation score: -0.003275\n",
      "Iteration 14, loss = 0.04321332\n",
      "Validation score: -0.000234\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 15, loss = 0.04317674\n",
      "Validation score: -0.000218\n",
      "Iteration 16, loss = 0.04316806\n",
      "Validation score: -0.000297\n",
      "Iteration 17, loss = 0.04316732\n",
      "Validation score: -0.000889\n",
      "Iteration 18, loss = 0.04315199\n",
      "Validation score: -0.005343\n",
      "Iteration 19, loss = 0.04316342\n",
      "Validation score: -0.001855\n",
      "Iteration 20, loss = 0.04316775\n",
      "Validation score: -0.000713\n",
      "Iteration 21, loss = 0.04315852\n",
      "Validation score: -0.001950\n",
      "Iteration 22, loss = 0.04316478\n",
      "Validation score: -0.006598\n",
      "Iteration 23, loss = 0.04318229\n",
      "Validation score: -0.003286\n",
      "Iteration 24, loss = 0.04316284\n",
      "Validation score: -0.000428\n",
      "Iteration 25, loss = 0.04317576\n",
      "Validation score: -0.000718\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 26, loss = 0.04315400\n",
      "Validation score: -0.001140\n",
      "Iteration 27, loss = 0.04314626\n",
      "Validation score: -0.002141\n",
      "Iteration 28, loss = 0.04314910\n",
      "Validation score: -0.001660\n",
      "Iteration 29, loss = 0.04315960\n",
      "Validation score: -0.001673\n",
      "Iteration 30, loss = 0.04314580\n",
      "Validation score: -0.001853\n",
      "Iteration 31, loss = 0.04314421\n",
      "Validation score: -0.001783\n",
      "Iteration 32, loss = 0.04314742\n",
      "Validation score: -0.001700\n",
      "Iteration 33, loss = 0.04314571\n",
      "Validation score: -0.002098\n",
      "Iteration 34, loss = 0.04314291\n",
      "Validation score: -0.001576\n",
      "Iteration 35, loss = 0.04314752\n",
      "Validation score: -0.001692\n",
      "Iteration 36, loss = 0.04314923\n",
      "Validation score: -0.001590\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 37, loss = 0.04314651\n",
      "Validation score: -0.002730\n",
      "Iteration 38, loss = 0.04314591\n",
      "Validation score: -0.002432\n",
      "Iteration 39, loss = 0.04314412\n",
      "Validation score: -0.002088\n",
      "Iteration 40, loss = 0.04314380\n",
      "Validation score: -0.002036\n",
      "Iteration 41, loss = 0.04314516\n",
      "Validation score: -0.002188\n",
      "Iteration 42, loss = 0.04314350\n",
      "Validation score: -0.001943\n",
      "Iteration 43, loss = 0.04314328\n",
      "Validation score: -0.001983\n",
      "Iteration 44, loss = 0.04314347\n",
      "Validation score: -0.001623\n",
      "Iteration 45, loss = 0.04314336\n",
      "Validation score: -0.001621\n",
      "Iteration 46, loss = 0.04314326\n",
      "Validation score: -0.001503\n",
      "Iteration 47, loss = 0.04314440\n",
      "Validation score: -0.001624\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000160\n",
      "Iteration 48, loss = 0.04314268\n",
      "Validation score: -0.001606\n",
      "Iteration 49, loss = 0.04314256\n",
      "Validation score: -0.001590\n",
      "Iteration 50, loss = 0.04314281\n",
      "Validation score: -0.001560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.73541308\n",
      "Validation score: -0.011859\n",
      "Iteration 2, loss = 0.04918249\n",
      "Validation score: -0.001456\n",
      "Iteration 3, loss = 0.04928911\n",
      "Validation score: -0.000137\n",
      "Iteration 4, loss = 0.04922271\n",
      "Validation score: -0.003199\n",
      "Iteration 5, loss = 0.04926317\n",
      "Validation score: -0.001431\n",
      "Iteration 6, loss = 0.04916143\n",
      "Validation score: -0.000543\n",
      "Iteration 7, loss = 0.04913462\n",
      "Validation score: -0.004137\n",
      "Iteration 8, loss = 0.04907623\n",
      "Validation score: -0.009414\n",
      "Iteration 9, loss = 0.04901959\n",
      "Validation score: -0.001886\n",
      "Iteration 10, loss = 0.04883653\n",
      "Validation score: -0.005977\n",
      "Iteration 11, loss = 0.04860950\n",
      "Validation score: -0.004113\n",
      "Iteration 12, loss = 0.04829372\n",
      "Validation score: 0.009463\n",
      "Iteration 13, loss = 0.04755013\n",
      "Validation score: -0.001070\n",
      "Iteration 14, loss = 0.04679188\n",
      "Validation score: -0.050271\n",
      "Iteration 15, loss = 0.04612801\n",
      "Validation score: -0.073571\n",
      "Iteration 16, loss = 0.04653155\n",
      "Validation score: 0.067332\n",
      "Iteration 17, loss = 0.04489773\n",
      "Validation score: 0.080743\n",
      "Iteration 18, loss = 0.04483339\n",
      "Validation score: 0.011676\n",
      "Iteration 19, loss = 0.04652234\n",
      "Validation score: -0.003334\n",
      "Iteration 20, loss = 0.04906928\n",
      "Validation score: -0.000601\n",
      "Iteration 21, loss = 0.04893229\n",
      "Validation score: 0.005285\n",
      "Iteration 22, loss = 0.04870894\n",
      "Validation score: 0.010363\n",
      "Iteration 23, loss = 0.04838092\n",
      "Validation score: 0.013088\n",
      "Iteration 24, loss = 0.04792630\n",
      "Validation score: 0.025449\n",
      "Iteration 25, loss = 0.04723154\n",
      "Validation score: 0.038716\n",
      "Iteration 26, loss = 0.04671215\n",
      "Validation score: 0.050352\n",
      "Iteration 27, loss = 0.04657826\n",
      "Validation score: -0.001553\n",
      "Iteration 28, loss = 0.04601892\n",
      "Validation score: 0.045534\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 29, loss = 0.04487751\n",
      "Validation score: 0.075286\n",
      "Iteration 30, loss = 0.04460189\n",
      "Validation score: 0.078076\n",
      "Iteration 31, loss = 0.04454831\n",
      "Validation score: 0.069229\n",
      "Iteration 32, loss = 0.04444583\n",
      "Validation score: 0.075067\n",
      "Iteration 33, loss = 0.04433345\n",
      "Validation score: 0.078194\n",
      "Iteration 34, loss = 0.04429094\n",
      "Validation score: 0.077375\n",
      "Iteration 35, loss = 0.04431952\n",
      "Validation score: 0.078091\n",
      "Iteration 36, loss = 0.04418895\n",
      "Validation score: 0.057794\n",
      "Iteration 37, loss = 0.04420268\n",
      "Validation score: 0.082412\n",
      "Iteration 38, loss = 0.04418874\n",
      "Validation score: 0.077048\n",
      "Iteration 39, loss = 0.04409098\n",
      "Validation score: 0.083796\n",
      "Iteration 40, loss = 0.04411647\n",
      "Validation score: 0.084454\n",
      "Iteration 41, loss = 0.04400271\n",
      "Validation score: 0.082074\n",
      "Iteration 42, loss = 0.04401531\n",
      "Validation score: 0.085909\n",
      "Iteration 43, loss = 0.04395916\n",
      "Validation score: 0.085899\n",
      "Iteration 44, loss = 0.04390228\n",
      "Validation score: 0.086003\n",
      "Iteration 45, loss = 0.04394732\n",
      "Validation score: 0.086385\n",
      "Iteration 46, loss = 0.04390140\n",
      "Validation score: 0.073420\n",
      "Iteration 47, loss = 0.04382459\n",
      "Validation score: 0.087184\n",
      "Iteration 48, loss = 0.04383781\n",
      "Validation score: 0.085769\n",
      "Iteration 49, loss = 0.04383896\n",
      "Validation score: 0.087315\n",
      "Iteration 50, loss = 0.04379262\n",
      "Validation score: 0.071401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 3.82995405\n",
      "Validation score: -0.001054\n",
      "Iteration 2, loss = 0.05569662\n",
      "Validation score: -0.000405\n",
      "Iteration 3, loss = 0.05574437\n",
      "Validation score: -0.004193\n",
      "Iteration 4, loss = 0.05572884\n",
      "Validation score: -0.000688\n",
      "Iteration 5, loss = 0.05576890\n",
      "Validation score: 0.000007\n",
      "Iteration 6, loss = 0.05572766\n",
      "Validation score: -0.018947\n",
      "Iteration 7, loss = 0.05577211\n",
      "Validation score: -0.004472\n",
      "Iteration 8, loss = 0.05579139\n",
      "Validation score: -0.001043\n",
      "Iteration 9, loss = 0.05573188\n",
      "Validation score: -0.001884\n",
      "Iteration 10, loss = 0.05574925\n",
      "Validation score: 0.000035\n",
      "Iteration 11, loss = 0.05577538\n",
      "Validation score: -0.005420\n",
      "Iteration 12, loss = 0.05573022\n",
      "Validation score: -0.000487\n",
      "Iteration 13, loss = 0.05572631\n",
      "Validation score: -0.000286\n",
      "Iteration 14, loss = 0.05574128\n",
      "Validation score: -0.003143\n",
      "Iteration 15, loss = 0.05575105\n",
      "Validation score: 0.000066\n",
      "Iteration 16, loss = 0.05575132\n",
      "Validation score: -0.002653\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 17, loss = 0.05569519\n",
      "Validation score: 0.000136\n",
      "Iteration 18, loss = 0.05572802\n",
      "Validation score: -0.001753\n",
      "Iteration 19, loss = 0.05568576\n",
      "Validation score: -0.000770\n",
      "Iteration 20, loss = 0.05568315\n",
      "Validation score: -0.001550\n",
      "Iteration 21, loss = 0.05568320\n",
      "Validation score: -0.000761\n",
      "Iteration 22, loss = 0.05569107\n",
      "Validation score: 0.000058\n",
      "Iteration 23, loss = 0.05568513\n",
      "Validation score: 0.000099\n",
      "Iteration 24, loss = 0.05569335\n",
      "Validation score: 0.000020\n",
      "Iteration 25, loss = 0.05569329\n",
      "Validation score: -0.000092\n",
      "Iteration 26, loss = 0.05569796\n",
      "Validation score: -0.000688\n",
      "Iteration 27, loss = 0.05570000\n",
      "Validation score: 0.000058\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 28, loss = 0.05568033\n",
      "Validation score: -0.000408\n",
      "Iteration 29, loss = 0.05567478\n",
      "Validation score: -0.000271\n",
      "Iteration 30, loss = 0.05568026\n",
      "Validation score: -0.000348\n",
      "Iteration 31, loss = 0.05567387\n",
      "Validation score: -0.000271\n",
      "Iteration 32, loss = 0.05567525\n",
      "Validation score: -0.000490\n",
      "Iteration 33, loss = 0.05567527\n",
      "Validation score: -0.000443\n",
      "Iteration 34, loss = 0.05567527\n",
      "Validation score: -0.000455\n",
      "Iteration 35, loss = 0.05567788\n",
      "Validation score: -0.000365\n",
      "Iteration 36, loss = 0.05567872\n",
      "Validation score: -0.000149\n",
      "Iteration 37, loss = 0.05567397\n",
      "Validation score: -0.000569\n",
      "Iteration 38, loss = 0.05567269\n",
      "Validation score: -0.000587\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 39, loss = 0.05567010\n",
      "Validation score: -0.000449\n",
      "Iteration 40, loss = 0.05567050\n",
      "Validation score: -0.000449\n",
      "Iteration 41, loss = 0.05567039\n",
      "Validation score: -0.000437\n",
      "Iteration 42, loss = 0.05567017\n",
      "Validation score: -0.000466\n",
      "Iteration 43, loss = 0.05567030\n",
      "Validation score: -0.000497\n",
      "Iteration 44, loss = 0.05567045\n",
      "Validation score: -0.000503\n",
      "Iteration 45, loss = 0.05567123\n",
      "Validation score: -0.000499\n",
      "Iteration 46, loss = 0.05567137\n",
      "Validation score: -0.000419\n",
      "Iteration 47, loss = 0.05567084\n",
      "Validation score: -0.000505\n",
      "Iteration 48, loss = 0.05567013\n",
      "Validation score: -0.000499\n",
      "Iteration 49, loss = 0.05567142\n",
      "Validation score: -0.000545\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000160\n",
      "Iteration 50, loss = 0.05566979\n",
      "Validation score: -0.000460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 45.22413369\n",
      "Validation score: -0.177688\n",
      "Iteration 2, loss = 0.68946468\n",
      "Validation score: -0.000983\n",
      "Iteration 3, loss = 0.69298264\n",
      "Validation score: -0.006758\n",
      "Iteration 4, loss = 0.69307968\n",
      "Validation score: -0.002383\n",
      "Iteration 5, loss = 0.69297334\n",
      "Validation score: -0.005244\n",
      "Iteration 6, loss = 0.69296412\n",
      "Validation score: -0.001212\n",
      "Iteration 7, loss = 0.69289850\n",
      "Validation score: -0.002922\n",
      "Iteration 8, loss = 0.69290022\n",
      "Validation score: -0.000461\n",
      "Iteration 9, loss = 0.69289793\n",
      "Validation score: -0.000021\n",
      "Iteration 10, loss = 0.69279410\n",
      "Validation score: -0.000062\n",
      "Iteration 11, loss = 0.69275413\n",
      "Validation score: -0.000001\n",
      "Iteration 12, loss = 0.69272736\n",
      "Validation score: -0.000857\n",
      "Iteration 13, loss = 0.69273639\n",
      "Validation score: -0.000026\n",
      "Iteration 14, loss = 0.69271449\n",
      "Validation score: -0.008038\n",
      "Iteration 15, loss = 0.69267431\n",
      "Validation score: -0.000840\n",
      "Iteration 16, loss = 0.69262628\n",
      "Validation score: -0.000352\n",
      "Iteration 17, loss = 0.69259466\n",
      "Validation score: -0.000680\n",
      "Iteration 18, loss = 0.69254445\n",
      "Validation score: -0.005573\n",
      "Iteration 19, loss = 0.69254647\n",
      "Validation score: -0.000558\n",
      "Iteration 20, loss = 0.69256949\n",
      "Validation score: -0.000347\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 21, loss = 0.69250529\n",
      "Validation score: -0.000005\n",
      "Iteration 22, loss = 0.69243300\n",
      "Validation score: -0.000572\n",
      "Iteration 23, loss = 0.69242624\n",
      "Validation score: -0.000206\n",
      "Iteration 24, loss = 0.69241336\n",
      "Validation score: -0.000047\n",
      "Iteration 25, loss = 0.69241230\n",
      "Validation score: -0.001622\n",
      "Iteration 26, loss = 0.69241189\n",
      "Validation score: -0.001286\n",
      "Iteration 27, loss = 0.69240151\n",
      "Validation score: -0.000005\n",
      "Iteration 28, loss = 0.69238928\n",
      "Validation score: -0.000050\n",
      "Iteration 29, loss = 0.69240712\n",
      "Validation score: -0.000005\n",
      "Iteration 30, loss = 0.69238411\n",
      "Validation score: -0.000086\n",
      "Iteration 31, loss = 0.69237334\n",
      "Validation score: -0.000209\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 32, loss = 0.69236074\n",
      "Validation score: -0.000138\n",
      "Iteration 33, loss = 0.69235197\n",
      "Validation score: -0.000167\n",
      "Iteration 34, loss = 0.69235047\n",
      "Validation score: -0.000141\n",
      "Iteration 35, loss = 0.69235132\n",
      "Validation score: -0.000148\n",
      "Iteration 36, loss = 0.69234720\n",
      "Validation score: -0.000051\n",
      "Iteration 37, loss = 0.69234771\n",
      "Validation score: -0.000068\n",
      "Iteration 38, loss = 0.69235150\n",
      "Validation score: -0.000061\n",
      "Iteration 39, loss = 0.69234960\n",
      "Validation score: -0.000241\n",
      "Iteration 40, loss = 0.69234733\n",
      "Validation score: -0.000025\n",
      "Iteration 41, loss = 0.69234474\n",
      "Validation score: -0.000072\n",
      "Iteration 42, loss = 0.69234049\n",
      "Validation score: -0.000053\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 43, loss = 0.69233806\n",
      "Validation score: -0.000054\n",
      "Iteration 44, loss = 0.69233672\n",
      "Validation score: -0.000070\n",
      "Iteration 45, loss = 0.69233630\n",
      "Validation score: -0.000128\n",
      "Iteration 46, loss = 0.69233719\n",
      "Validation score: -0.000131\n",
      "Iteration 47, loss = 0.69233569\n",
      "Validation score: -0.000152\n",
      "Iteration 48, loss = 0.69233665\n",
      "Validation score: -0.000142\n",
      "Iteration 49, loss = 0.69233535\n",
      "Validation score: -0.000130\n",
      "Iteration 50, loss = 0.69233520\n",
      "Validation score: -0.000108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 42.18818745\n",
      "Validation score: -2.875132\n",
      "Iteration 2, loss = 0.52085644\n",
      "Validation score: -0.000185\n",
      "Iteration 3, loss = 0.51874687\n",
      "Validation score: -0.001242\n",
      "Iteration 4, loss = 0.51876464\n",
      "Validation score: -0.010485\n",
      "Iteration 5, loss = 0.51878127\n",
      "Validation score: -0.009176\n",
      "Iteration 6, loss = 0.51876579\n",
      "Validation score: -0.000291\n",
      "Iteration 7, loss = 0.51870023\n",
      "Validation score: -0.029104\n",
      "Iteration 8, loss = 0.51877085\n",
      "Validation score: -0.018785\n",
      "Iteration 9, loss = 0.51869277\n",
      "Validation score: -0.001962\n",
      "Iteration 10, loss = 0.51861914\n",
      "Validation score: -0.007249\n",
      "Iteration 11, loss = 0.51856839\n",
      "Validation score: -0.000324\n",
      "Iteration 12, loss = 0.51855285\n",
      "Validation score: -0.000479\n",
      "Iteration 13, loss = 0.51852385\n",
      "Validation score: -0.006950\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 14, loss = 0.51853043\n",
      "Validation score: -0.004080\n",
      "Iteration 15, loss = 0.51845605\n",
      "Validation score: -0.000154\n",
      "Iteration 16, loss = 0.51846645\n",
      "Validation score: -0.003464\n",
      "Iteration 17, loss = 0.51844635\n",
      "Validation score: -0.000052\n",
      "Iteration 18, loss = 0.51845032\n",
      "Validation score: -0.000010\n",
      "Iteration 19, loss = 0.51843646\n",
      "Validation score: -0.000747\n",
      "Iteration 20, loss = 0.51842262\n",
      "Validation score: -0.000384\n",
      "Iteration 21, loss = 0.51844641\n",
      "Validation score: -0.002054\n",
      "Iteration 22, loss = 0.51842803\n",
      "Validation score: -0.000052\n",
      "Iteration 23, loss = 0.51841506\n",
      "Validation score: -0.000085\n",
      "Iteration 24, loss = 0.51842263\n",
      "Validation score: -0.000971\n",
      "Iteration 25, loss = 0.51840391\n",
      "Validation score: -0.000002\n",
      "Iteration 26, loss = 0.51842525\n",
      "Validation score: -0.002616\n",
      "Iteration 27, loss = 0.51839129\n",
      "Validation score: -0.000008\n",
      "Iteration 28, loss = 0.51838671\n",
      "Validation score: -0.000271\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 29, loss = 0.51838929\n",
      "Validation score: -0.000360\n",
      "Iteration 30, loss = 0.51837478\n",
      "Validation score: -0.000561\n",
      "Iteration 31, loss = 0.51837242\n",
      "Validation score: -0.000721\n",
      "Iteration 32, loss = 0.51836933\n",
      "Validation score: -0.000641\n",
      "Iteration 33, loss = 0.51836951\n",
      "Validation score: -0.000919\n",
      "Iteration 34, loss = 0.51837454\n",
      "Validation score: -0.001328\n",
      "Iteration 35, loss = 0.51837062\n",
      "Validation score: -0.000744\n",
      "Iteration 36, loss = 0.51836872\n",
      "Validation score: -0.000940\n",
      "Iteration 37, loss = 0.51836623\n",
      "Validation score: -0.000636\n",
      "Iteration 38, loss = 0.51836428\n",
      "Validation score: -0.000546\n",
      "Iteration 39, loss = 0.51836402\n",
      "Validation score: -0.000767\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 40, loss = 0.51836267\n",
      "Validation score: -0.001288\n",
      "Iteration 41, loss = 0.51836230\n",
      "Validation score: -0.001358\n",
      "Iteration 42, loss = 0.51836183\n",
      "Validation score: -0.001235\n",
      "Iteration 43, loss = 0.51835955\n",
      "Validation score: -0.000915\n",
      "Iteration 44, loss = 0.51835937\n",
      "Validation score: -0.000803\n",
      "Iteration 45, loss = 0.51835932\n",
      "Validation score: -0.000731\n",
      "Iteration 46, loss = 0.51835819\n",
      "Validation score: -0.000600\n",
      "Iteration 47, loss = 0.51835840\n",
      "Validation score: -0.000575\n",
      "Iteration 48, loss = 0.51835823\n",
      "Validation score: -0.000554\n",
      "Iteration 49, loss = 0.51835772\n",
      "Validation score: -0.000530\n",
      "Iteration 50, loss = 0.51835935\n",
      "Validation score: -0.000445\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 3.59182736\n",
      "Validation score: -0.009676\n",
      "Iteration 2, loss = 0.07203363\n",
      "Validation score: -0.000460\n",
      "Iteration 3, loss = 0.07218122\n",
      "Validation score: -0.000475\n",
      "Iteration 4, loss = 0.07214524\n",
      "Validation score: -0.002243\n",
      "Iteration 5, loss = 0.07212998\n",
      "Validation score: -0.001752\n",
      "Iteration 6, loss = 0.07213884\n",
      "Validation score: -0.013679\n",
      "Iteration 7, loss = 0.07219141\n",
      "Validation score: -0.002088\n",
      "Iteration 8, loss = 0.07214505\n",
      "Validation score: -0.000329\n",
      "Iteration 9, loss = 0.07217138\n",
      "Validation score: -0.004858\n",
      "Iteration 10, loss = 0.07214564\n",
      "Validation score: -0.000176\n",
      "Iteration 11, loss = 0.07211898\n",
      "Validation score: -0.001697\n",
      "Iteration 12, loss = 0.07215227\n",
      "Validation score: -0.000370\n",
      "Iteration 13, loss = 0.07213549\n",
      "Validation score: -0.000225\n",
      "Iteration 14, loss = 0.07211299\n",
      "Validation score: -0.010133\n",
      "Iteration 15, loss = 0.07217228\n",
      "Validation score: -0.000509\n",
      "Iteration 16, loss = 0.07213046\n",
      "Validation score: -0.002073\n",
      "Iteration 17, loss = 0.07212549\n",
      "Validation score: -0.001095\n",
      "Iteration 18, loss = 0.07214404\n",
      "Validation score: -0.003578\n",
      "Iteration 19, loss = 0.07213011\n",
      "Validation score: -0.001710\n",
      "Iteration 20, loss = 0.07211443\n",
      "Validation score: -0.000476\n",
      "Iteration 21, loss = 0.07215415\n",
      "Validation score: -0.000606\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 22, loss = 0.07205951\n",
      "Validation score: -0.002335\n",
      "Iteration 23, loss = 0.07209102\n",
      "Validation score: -0.000528\n",
      "Iteration 24, loss = 0.07206783\n",
      "Validation score: -0.002563\n",
      "Iteration 25, loss = 0.07206277\n",
      "Validation score: -0.000468\n",
      "Iteration 26, loss = 0.07207075\n",
      "Validation score: -0.000581\n",
      "Iteration 27, loss = 0.07207182\n",
      "Validation score: -0.000476\n",
      "Iteration 28, loss = 0.07207301\n",
      "Validation score: -0.000672\n",
      "Iteration 29, loss = 0.07206655\n",
      "Validation score: -0.000522\n",
      "Iteration 30, loss = 0.07208154\n",
      "Validation score: -0.000476\n",
      "Iteration 31, loss = 0.07208624\n",
      "Validation score: -0.000683\n",
      "Iteration 32, loss = 0.07207377\n",
      "Validation score: -0.000848\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 33, loss = 0.07206260\n",
      "Validation score: -0.000688\n",
      "Iteration 34, loss = 0.07206005\n",
      "Validation score: -0.000853\n",
      "Iteration 35, loss = 0.07205130\n",
      "Validation score: -0.001036\n",
      "Iteration 36, loss = 0.07205660\n",
      "Validation score: -0.001267\n",
      "Iteration 37, loss = 0.07205241\n",
      "Validation score: -0.001166\n",
      "Iteration 38, loss = 0.07205162\n",
      "Validation score: -0.001069\n",
      "Iteration 39, loss = 0.07205419\n",
      "Validation score: -0.001305\n",
      "Iteration 40, loss = 0.07205250\n",
      "Validation score: -0.001157\n",
      "Iteration 41, loss = 0.07205813\n",
      "Validation score: -0.001035\n",
      "Iteration 42, loss = 0.07205810\n",
      "Validation score: -0.001308\n",
      "Iteration 43, loss = 0.07205109\n",
      "Validation score: -0.001194\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 44, loss = 0.07204876\n",
      "Validation score: -0.001102\n",
      "Iteration 45, loss = 0.07204785\n",
      "Validation score: -0.001078\n",
      "Iteration 46, loss = 0.07204779\n",
      "Validation score: -0.001064\n",
      "Iteration 47, loss = 0.07205041\n",
      "Validation score: -0.001148\n",
      "Iteration 48, loss = 0.07204761\n",
      "Validation score: -0.001082\n",
      "Iteration 49, loss = 0.07204784\n",
      "Validation score: -0.001094\n",
      "Iteration 50, loss = 0.07204868\n",
      "Validation score: -0.001109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.08406475\n",
      "Validation score: 0.000615\n",
      "Iteration 2, loss = 0.04407895\n",
      "Validation score: -0.004379\n",
      "Iteration 3, loss = 0.04420841\n",
      "Validation score: -0.002426\n",
      "Iteration 4, loss = 0.04412632\n",
      "Validation score: -0.001717\n",
      "Iteration 5, loss = 0.04415098\n",
      "Validation score: 0.000608\n",
      "Iteration 6, loss = 0.04409065\n",
      "Validation score: -0.001641\n",
      "Iteration 7, loss = 0.04408481\n",
      "Validation score: -0.004245\n",
      "Iteration 8, loss = 0.04407731\n",
      "Validation score: -0.000523\n",
      "Iteration 9, loss = 0.04407397\n",
      "Validation score: -0.012233\n",
      "Iteration 10, loss = 0.04416061\n",
      "Validation score: -0.003627\n",
      "Iteration 11, loss = 0.04408579\n",
      "Validation score: -0.000216\n",
      "Iteration 12, loss = 0.04407904\n",
      "Validation score: -0.000538\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 13, loss = 0.04409865\n",
      "Validation score: 0.000718\n",
      "Iteration 14, loss = 0.04404157\n",
      "Validation score: -0.000413\n",
      "Iteration 15, loss = 0.04403547\n",
      "Validation score: -0.001314\n",
      "Iteration 16, loss = 0.04404803\n",
      "Validation score: 0.000045\n",
      "Iteration 17, loss = 0.04403663\n",
      "Validation score: 0.000748\n",
      "Iteration 18, loss = 0.04403766\n",
      "Validation score: 0.000651\n",
      "Iteration 19, loss = 0.04404727\n",
      "Validation score: 0.000680\n",
      "Iteration 20, loss = 0.04403710\n",
      "Validation score: 0.000152\n",
      "Iteration 21, loss = 0.04404074\n",
      "Validation score: 0.000740\n",
      "Iteration 22, loss = 0.04403093\n",
      "Validation score: 0.000526\n",
      "Iteration 23, loss = 0.04405740\n",
      "Validation score: 0.001879\n",
      "Iteration 24, loss = 0.04403611\n",
      "Validation score: 0.002286\n",
      "Iteration 25, loss = 0.04402532\n",
      "Validation score: 0.003492\n",
      "Iteration 26, loss = 0.04401653\n",
      "Validation score: 0.003674\n",
      "Iteration 27, loss = 0.04399940\n",
      "Validation score: 0.004260\n",
      "Iteration 28, loss = 0.04398145\n",
      "Validation score: 0.004613\n",
      "Iteration 29, loss = 0.04398222\n",
      "Validation score: 0.005056\n",
      "Iteration 30, loss = 0.04396591\n",
      "Validation score: 0.003999\n",
      "Iteration 31, loss = 0.04397839\n",
      "Validation score: 0.005848\n",
      "Iteration 32, loss = 0.04393149\n",
      "Validation score: 0.006397\n",
      "Iteration 33, loss = 0.04391475\n",
      "Validation score: 0.004530\n",
      "Iteration 34, loss = 0.04393786\n",
      "Validation score: 0.007513\n",
      "Iteration 35, loss = 0.04389427\n",
      "Validation score: 0.008152\n",
      "Iteration 36, loss = 0.04385599\n",
      "Validation score: 0.009095\n",
      "Iteration 37, loss = 0.04382242\n",
      "Validation score: 0.009563\n",
      "Iteration 38, loss = 0.04380244\n",
      "Validation score: 0.009305\n",
      "Iteration 39, loss = 0.04377569\n",
      "Validation score: 0.012618\n",
      "Iteration 40, loss = 0.04374353\n",
      "Validation score: 0.013741\n",
      "Iteration 41, loss = 0.04366629\n",
      "Validation score: 0.014428\n",
      "Iteration 42, loss = 0.04365984\n",
      "Validation score: 0.014496\n",
      "Iteration 43, loss = 0.04358214\n",
      "Validation score: 0.019072\n",
      "Iteration 44, loss = 0.04355307\n",
      "Validation score: 0.020614\n",
      "Iteration 45, loss = 0.04339649\n",
      "Validation score: 0.024052\n",
      "Iteration 46, loss = 0.04334738\n",
      "Validation score: 0.026541\n",
      "Iteration 47, loss = 0.04318794\n",
      "Validation score: 0.027986\n",
      "Iteration 48, loss = 0.04309341\n",
      "Validation score: 0.029664\n",
      "Iteration 49, loss = 0.04303148\n",
      "Validation score: 0.030620\n",
      "Iteration 50, loss = 0.04286601\n",
      "Validation score: 0.039941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2969810611454230837818360259493474366065519887429699395167797622623330316952003121557423197184984316050404362013550055522304.00000000\n",
      "Validation score: -502525568072348520620801494617480753283733038085803979574394744520232545859976298496.000000\n",
      "Iteration 2, loss = 21200465227036425253360678180787869572703963768596050571434848594176520657800790608601104620700445946474580599865915985625088.00000000\n",
      "Validation score: -1543263002703252535062006850555624736797246808173331099675906387138134824452096.000000\n",
      "Iteration 3, loss = 22896485230742945936746912252041847666248085291499102239332549081395536751559379744387570368382953353140892745935475307446272.00000000\n",
      "Validation score: -6445203503447104176561168705780253703758419540961928641021762922983494516736.000000\n",
      "Iteration 4, loss = 22916770906177826190840934903494128978395778885011234459477353922827243814186314751362019528711163713583994480107031560716288.00000000\n",
      "Validation score: -2422961044775398660264256037087156974757672557342570195964584242070945792.000000\n",
      "Iteration 5, loss = 22916049351377169799772455475300876390178366277478482042182934303995441748232237770808364410232458828547764942294057675128832.00000000\n",
      "Validation score: -231657729658519541711055842447794014868665708040942424005417837264896.000000\n",
      "Iteration 6, loss = 22915076193419467674507211421219953509807481559510512557310954139498570633555532306833402252148148701279091547735671223353344.00000000\n",
      "Validation score: -1461063284832217036802943674134595914983390130303129976607604736.000000\n",
      "Iteration 7, loss = 22914100064213990705085101950607781896569991287634515731279535070673901642102772846897848483058287693882814991419787744116736.00000000\n",
      "Validation score: -2326713736498043188629870103451085434491139075810542464532480.000000\n",
      "Iteration 8, loss = 22913123940521336984826156621483247888438789814924498828237473750515543625184485855556769468431618965957044632941480447574016.00000000\n",
      "Validation score: -1003041751859859093899141802698023070604829491971634495488.000000\n",
      "Iteration 9, loss = 22912147857979029107111511817474887358002669046605664809639973109575331874195472193533119716437558720477753589480082687131648.00000000\n",
      "Validation score: -105736205526735231909324565195252098905233532831924224.000000\n",
      "Iteration 10, loss = 22911171817011946607675947255506642018987981522974603156775135112302663813377566859978433269800011670640727136638507883167744.00000000\n",
      "Validation score: -1089421414548514189984397443048634986676894040064.000000\n",
      "Iteration 11, loss = 22910195817623452599497995064760849607609329574654515847052996472752392283402003978216674247810017833411652263199497766567936.00000000\n",
      "Validation score: -823011174189541772916662349598915718153240576.000000\n",
      "Iteration 12, loss = 22909219859811813858151568156315327687186282670919199626752462850859935303531792777987308069436300998929721009860214769319936.00000000\n",
      "Validation score: -412440279411263598685355500304483863232512.000000\n",
      "Iteration 13, loss = 22908243943575287765040248345914982263116023123694341739422244273281228063866056360193699695213811102538131878243009195671552.00000000\n",
      "Validation score: -47820420144552949653858677130946150400.000000\n",
      "Iteration 14, loss = 22907268068912080033630796424973705772222603879491027163594974783635050194102544117140661564291741878202118905058764647301120.00000000\n",
      "Validation score: -712092007024507595174173231546368.000000\n",
      "Iteration 15, loss = 22906292235820433954071297566237036883019626514212778888724070958658112640594549956477407949554382479070890283317613236846592.00000000\n",
      "Validation score: -284121007742153671031901913088.000000\n",
      "Iteration 16, loss = 22905316444298588119424671394784058485059499025089065152897851558447384935113424721435102894669135130895657436492281013075968.00000000\n",
      "Validation score: -168420228599495469440172032.000000\n",
      "Iteration 17, loss = 22904340694344729454817016511362839899321500043934751929188559360062681049029145546646357921917645858049667323144027322187776.00000000\n",
      "Validation score: -21442809881758567235584.000000\n",
      "Iteration 18, loss = 22903364985957101250396418088718919794319231146653362207049610940240711928695006339760387304184203813682128136282984276819968.00000000\n",
      "Validation score: -427931854857450560.000000\n",
      "Iteration 19, loss = 22902389319133989070077451228595938849217036117214911738220303225475861251701788588188857377305080497524218994755938564440064.00000000\n",
      "Validation score: -95205791708956.062500\n",
      "Iteration 20, loss = 22901413693873589233156545627074877942916580744782375998503074626107425818583355555400480121995695788745180396198961658986496.00000000\n",
      "Validation score: -68283627723.333496\n",
      "Iteration 21, loss = 22900438110174088664759799884903806396397143661170620960970167919195219600709684376027867060537695711718259299173312906657792.00000000\n",
      "Validation score: -9538258.509766\n",
      "Iteration 22, loss = 22899462568033730655035299174828262878172326442283169615074999681475953544434068957720232465815369419592663896689124420091904.00000000\n",
      "Validation score: -243.716558\n",
      "Iteration 23, loss = 22898487067450772585386625312593153393639311400045709204366279939605562839855632401380941298363666847711592690368746503536640.00000000\n",
      "Validation score: -0.007861\n",
      "Iteration 24, loss = 22897511608423448351791532375611105053389312953013653215567229637041275604163782485823107372633103294428260334147499141890048.00000000\n",
      "Validation score: -0.007683\n",
      "Iteration 25, loss = 22896536190949996547312939988961200746974739098416469886766167533880061369129870054277894732291080985493878251498108383920128.00000000\n",
      "Validation score: -0.003564\n",
      "Iteration 26, loss = 22895560815028599399991781205725054016413674889394970439670238590541992691541929176959864670402359017883696631444427511955456.00000000\n",
      "Validation score: -0.016415\n",
      "Iteration 27, loss = 22894585480657533079572300032313393982948076952571061123288544100241970419826855212444583064369435036532901053758431085723648.00000000\n",
      "Validation score: -0.004704\n",
      "Iteration 28, loss = 22893610187834998602436091712473657304440804655781772164788620289959032769100454488618812124124615848008728785613596643033088.00000000\n",
      "Validation score: -0.001695\n",
      "Iteration 29, loss = 22892634936559225167475744775952015312521878838908462299528590286510666441970191719877615434901529823266397711407838104911872.00000000\n",
      "Validation score: -0.001408\n",
      "Iteration 30, loss = 22891659726828437276498682204828183559860126763158435511501479400074616726461588556198006352716918405863128946001663328518144.00000000\n",
      "Validation score: -0.000095\n",
      "Iteration 31, loss = 22890684558640897007993651362513523830813924319131433795621095473946560227255711162901400067322618458540117760554828681969664.00000000\n",
      "Validation score: -0.004145\n",
      "Iteration 32, loss = 22889709431994838257938406326420663235974485925382870638610659451583725061541967318800910393169145279650578809002654150164480.00000000\n",
      "Validation score: -0.004925\n",
      "Iteration 33, loss = 22888734346888471436884873435629949991127058107097885770367903193244632273600049480619399998622579530557742897593429398650880.00000000\n",
      "Validation score: -0.002740\n",
      "Iteration 34, loss = 22887759303319997561214647933888820754134500232113509418060362925908320078545763976243631093615228017828847293500631965237248.00000000\n",
      "Validation score: -0.004331\n",
      "Iteration 35, loss = 22886784301287664618160980541609269972471607455007319322506553042951240837314347777740868180248266822011096959271800026431488.00000000\n",
      "Validation score: -0.005238\n",
      "Iteration 36, loss = 22885809340789711200786790883870380535690787773008783721794792304470364081677151728342275302189098168855703318379659631001600.00000000\n",
      "Validation score: -0.000098\n",
      "Iteration 37, loss = 22884834421824404084665991871749970007111610655391699362203986370401107830897185057787317878406445848501858411521373210935296.00000000\n",
      "Validation score: -0.001672\n",
      "Iteration 38, loss = 22883859544389916103669185462996740370829773997948767962711084567884061812598595707454456743531295103128818888645981920821248.00000000\n",
      "Validation score: -0.004637\n",
      "Iteration 39, loss = 22882884708484523427540615664021420748087234427301895772325188190134126875208279035919257774966143577671770329525460320387072.00000000\n",
      "Validation score: -0.003025\n",
      "Iteration 40, loss = 22881909914106431769747043266237903575708044889962167769578931280770082648423984435486533411860185006095946770870692011311104.00000000\n",
      "Validation score: -0.000692\n",
      "Iteration 41, loss = 22880935161253860935010725704059448627399839068462833187100241333329933005689290491715246781013273904560572558004778786881536.00000000\n",
      "Validation score: -0.021554\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 42, loss = 22880222297960135226773195994667110034460416914497485489288751393629764352971394355438171598438355753316232387853481385394176.00000000\n",
      "Validation score: -0.001472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 43, loss = 22879990805523189622990802133335444943427296548577981557132235571521427892250865603498634146036204715701053614330669483163648.00000000\n",
      "Validation score: -0.004095\n",
      "Iteration 44, loss = 22879795431023894578545953945404791722657910102072265217170970885926716628375980165545820757069254252247212959447597419855872.00000000\n",
      "Validation score: -0.007080\n",
      "Iteration 45, loss = 22879600490587523903172204060770693731836569063451792852180428424162614127769914219581447758060945993012689728508569474564096.00000000\n",
      "Validation score: -0.004740\n",
      "Iteration 46, loss = 22879405556988930260459304071470362719606189201361565476971361449323047876197931785820207012980310440177423806909614148026368.00000000\n",
      "Validation score: -0.004131\n",
      "Iteration 47, loss = 22879210625113157000191804923152917988762563302443317549164970682038229062612831926612289583771340561587272662793795361832960.00000000\n",
      "Validation score: -0.001744\n",
      "Iteration 48, loss = 22879015694898940040555468402235634548457844721000927013790433690160887294731225437328555794577842305170371219773822060199936.00000000\n",
      "Validation score: -0.001795\n",
      "Iteration 49, loss = 22878820766345541939179303525084955101784641605207797906527393261251620483188051204335119658348568069441226660476942215544832.00000000\n",
      "Validation score: -0.003233\n",
      "Iteration 50, loss = 22878625839452920422296820362702777638092211746997437465089969045552755896745821647869529112131535507817868059066501253038080.00000000\n",
      "Validation score: -0.002486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 3.69962549\n",
      "Validation score: -0.012877\n",
      "Iteration 2, loss = 0.06557116\n",
      "Validation score: -0.001600\n",
      "Iteration 3, loss = 0.06556261\n",
      "Validation score: -0.002009\n",
      "Iteration 4, loss = 0.06556205\n",
      "Validation score: -0.003671\n",
      "Iteration 5, loss = 0.06555403\n",
      "Validation score: -0.000004\n",
      "Iteration 6, loss = 0.06556839\n",
      "Validation score: -0.002135\n",
      "Iteration 7, loss = 0.06553891\n",
      "Validation score: -0.000507\n",
      "Iteration 8, loss = 0.06552986\n",
      "Validation score: -0.002777\n",
      "Iteration 9, loss = 0.06553621\n",
      "Validation score: -0.007181\n",
      "Iteration 10, loss = 0.06560269\n",
      "Validation score: -0.000055\n",
      "Iteration 11, loss = 0.06556037\n",
      "Validation score: -0.000672\n",
      "Iteration 12, loss = 0.06555619\n",
      "Validation score: -0.001531\n",
      "Iteration 13, loss = 0.06554416\n",
      "Validation score: -0.002794\n",
      "Iteration 14, loss = 0.06551012\n",
      "Validation score: -0.000116\n",
      "Iteration 15, loss = 0.06550580\n",
      "Validation score: -0.000065\n",
      "Iteration 16, loss = 0.06554668\n",
      "Validation score: -0.006342\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 17, loss = 0.06558584\n",
      "Validation score: -0.000115\n",
      "Iteration 18, loss = 0.06552125\n",
      "Validation score: -0.000087\n",
      "Iteration 19, loss = 0.06549622\n",
      "Validation score: -0.000273\n",
      "Iteration 20, loss = 0.06550805\n",
      "Validation score: -0.000035\n",
      "Iteration 21, loss = 0.06550562\n",
      "Validation score: -0.000028\n",
      "Iteration 22, loss = 0.06549163\n",
      "Validation score: -0.000029\n",
      "Iteration 23, loss = 0.06548361\n",
      "Validation score: -0.000073\n",
      "Iteration 24, loss = 0.06549135\n",
      "Validation score: -0.000698\n",
      "Iteration 25, loss = 0.06549561\n",
      "Validation score: -0.000024\n",
      "Iteration 26, loss = 0.06550205\n",
      "Validation score: -0.000286\n",
      "Iteration 27, loss = 0.06549086\n",
      "Validation score: -0.000019\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 28, loss = 0.06548850\n",
      "Validation score: -0.000025\n",
      "Iteration 29, loss = 0.06547437\n",
      "Validation score: -0.000028\n",
      "Iteration 30, loss = 0.06547478\n",
      "Validation score: -0.000063\n",
      "Iteration 31, loss = 0.06547706\n",
      "Validation score: -0.000028\n",
      "Iteration 32, loss = 0.06547564\n",
      "Validation score: -0.000019\n",
      "Iteration 33, loss = 0.06547404\n",
      "Validation score: -0.000019\n",
      "Iteration 34, loss = 0.06547392\n",
      "Validation score: -0.000018\n",
      "Iteration 35, loss = 0.06547565\n",
      "Validation score: -0.000046\n",
      "Iteration 36, loss = 0.06547447\n",
      "Validation score: -0.000019\n",
      "Iteration 37, loss = 0.06547629\n",
      "Validation score: -0.000018\n",
      "Iteration 38, loss = 0.06548037\n",
      "Validation score: -0.000021\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 39, loss = 0.06547097\n",
      "Validation score: -0.000048\n",
      "Iteration 40, loss = 0.06547215\n",
      "Validation score: -0.000040\n",
      "Iteration 41, loss = 0.06547190\n",
      "Validation score: -0.000051\n",
      "Iteration 42, loss = 0.06547075\n",
      "Validation score: -0.000030\n",
      "Iteration 43, loss = 0.06547075\n",
      "Validation score: -0.000024\n",
      "Iteration 44, loss = 0.06547131\n",
      "Validation score: -0.000029\n",
      "Iteration 45, loss = 0.06547084\n",
      "Validation score: -0.000043\n",
      "Iteration 46, loss = 0.06547137\n",
      "Validation score: -0.000037\n",
      "Iteration 47, loss = 0.06547082\n",
      "Validation score: -0.000021\n",
      "Iteration 48, loss = 0.06547095\n",
      "Validation score: -0.000029\n",
      "Iteration 49, loss = 0.06547186\n",
      "Validation score: -0.000045\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000160\n",
      "Iteration 50, loss = 0.06547068\n",
      "Validation score: -0.000035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 6.38105921\n",
      "Validation score: -0.141486\n",
      "Iteration 2, loss = 0.09738542\n",
      "Validation score: -0.000051\n",
      "Iteration 3, loss = 0.09747135\n",
      "Validation score: -0.000074\n",
      "Iteration 4, loss = 0.09744608\n",
      "Validation score: -0.001303\n",
      "Iteration 5, loss = 0.09745744\n",
      "Validation score: -0.014959\n",
      "Iteration 6, loss = 0.09742841\n",
      "Validation score: -0.002373\n",
      "Iteration 7, loss = 0.09746341\n",
      "Validation score: -0.000044\n",
      "Iteration 8, loss = 0.09740121\n",
      "Validation score: -0.006842\n",
      "Iteration 9, loss = 0.09745852\n",
      "Validation score: -0.000284\n",
      "Iteration 10, loss = 0.09742410\n",
      "Validation score: -0.029524\n",
      "Iteration 11, loss = 0.09747831\n",
      "Validation score: -0.003887\n",
      "Iteration 12, loss = 0.09746049\n",
      "Validation score: -0.022195\n",
      "Iteration 13, loss = 0.09744256\n",
      "Validation score: 0.000296\n",
      "Iteration 14, loss = 0.09745799\n",
      "Validation score: -0.005600\n",
      "Iteration 15, loss = 0.09742537\n",
      "Validation score: -0.000753\n",
      "Iteration 16, loss = 0.09741596\n",
      "Validation score: -0.009263\n",
      "Iteration 17, loss = 0.09740587\n",
      "Validation score: -0.000223\n",
      "Iteration 18, loss = 0.09743229\n",
      "Validation score: -0.007745\n",
      "Iteration 19, loss = 0.09747022\n",
      "Validation score: -0.018664\n",
      "Iteration 20, loss = 0.09743649\n",
      "Validation score: 0.000286\n",
      "Iteration 21, loss = 0.09745647\n",
      "Validation score: -0.002232\n",
      "Iteration 22, loss = 0.09738644\n",
      "Validation score: -0.015665\n",
      "Iteration 23, loss = 0.09744809\n",
      "Validation score: -0.000281\n",
      "Iteration 24, loss = 0.09740319\n",
      "Validation score: -0.001951\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 25, loss = 0.09733822\n",
      "Validation score: -0.000252\n",
      "Iteration 26, loss = 0.09737251\n",
      "Validation score: -0.002377\n",
      "Iteration 27, loss = 0.09735686\n",
      "Validation score: -0.001970\n",
      "Iteration 28, loss = 0.09736716\n",
      "Validation score: -0.001196\n",
      "Iteration 29, loss = 0.09736208\n",
      "Validation score: -0.003184\n",
      "Iteration 30, loss = 0.09735221\n",
      "Validation score: -0.001624\n",
      "Iteration 31, loss = 0.09734563\n",
      "Validation score: -0.005183\n",
      "Iteration 32, loss = 0.09734670\n",
      "Validation score: -0.002822\n",
      "Iteration 33, loss = 0.09735583\n",
      "Validation score: -0.003641\n",
      "Iteration 34, loss = 0.09734204\n",
      "Validation score: -0.002860\n",
      "Iteration 35, loss = 0.09734295\n",
      "Validation score: -0.003587\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 36, loss = 0.09735163\n",
      "Validation score: -0.003394\n",
      "Iteration 37, loss = 0.09733120\n",
      "Validation score: -0.002526\n",
      "Iteration 38, loss = 0.09733593\n",
      "Validation score: -0.002567\n",
      "Iteration 39, loss = 0.09733135\n",
      "Validation score: -0.002644\n",
      "Iteration 40, loss = 0.09733363\n",
      "Validation score: -0.002469\n",
      "Iteration 41, loss = 0.09733122\n",
      "Validation score: -0.002634\n",
      "Iteration 42, loss = 0.09734777\n",
      "Validation score: -0.003236\n",
      "Iteration 43, loss = 0.09733305\n",
      "Validation score: -0.002839\n",
      "Iteration 44, loss = 0.09733001\n",
      "Validation score: -0.002540\n",
      "Iteration 45, loss = 0.09733228\n",
      "Validation score: -0.002510\n",
      "Iteration 46, loss = 0.09733097\n",
      "Validation score: -0.002453\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 47, loss = 0.09732832\n",
      "Validation score: -0.002396\n",
      "Iteration 48, loss = 0.09732756\n",
      "Validation score: -0.002436\n",
      "Iteration 49, loss = 0.09732818\n",
      "Validation score: -0.002656\n",
      "Iteration 50, loss = 0.09732827\n",
      "Validation score: -0.002442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 12.06036581\n",
      "Validation score: -0.197547\n",
      "Iteration 2, loss = 0.17435422\n",
      "Validation score: -0.000489\n",
      "Iteration 3, loss = 0.17441941\n",
      "Validation score: -0.000318\n",
      "Iteration 4, loss = 0.17438204\n",
      "Validation score: -0.000010\n",
      "Iteration 5, loss = 0.17439317\n",
      "Validation score: -0.002847\n",
      "Iteration 6, loss = 0.17441776\n",
      "Validation score: -0.000298\n",
      "Iteration 7, loss = 0.17437744\n",
      "Validation score: -0.001252\n",
      "Iteration 8, loss = 0.17435811\n",
      "Validation score: -0.000723\n",
      "Iteration 9, loss = 0.17440702\n",
      "Validation score: -0.000970\n",
      "Iteration 10, loss = 0.17436796\n",
      "Validation score: -0.000502\n",
      "Iteration 11, loss = 0.17437124\n",
      "Validation score: -0.001646\n",
      "Iteration 12, loss = 0.17433974\n",
      "Validation score: -0.001667\n",
      "Iteration 13, loss = 0.17437337\n",
      "Validation score: -0.001619\n",
      "Iteration 14, loss = 0.17426499\n",
      "Validation score: -0.002156\n",
      "Iteration 15, loss = 0.17431626\n",
      "Validation score: -0.000455\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 16, loss = 0.17428326\n",
      "Validation score: -0.000503\n",
      "Iteration 17, loss = 0.17429155\n",
      "Validation score: -0.000751\n",
      "Iteration 18, loss = 0.17428383\n",
      "Validation score: -0.000819\n",
      "Iteration 19, loss = 0.17429097\n",
      "Validation score: -0.000085\n",
      "Iteration 20, loss = 0.17429112\n",
      "Validation score: -0.000039\n",
      "Iteration 21, loss = 0.17428007\n",
      "Validation score: -0.000041\n",
      "Iteration 22, loss = 0.17428261\n",
      "Validation score: -0.000525\n",
      "Iteration 23, loss = 0.17426984\n",
      "Validation score: -0.001507\n",
      "Iteration 24, loss = 0.17427945\n",
      "Validation score: -0.000035\n",
      "Iteration 25, loss = 0.17426831\n",
      "Validation score: -0.000036\n",
      "Iteration 26, loss = 0.17426590\n",
      "Validation score: -0.000054\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 27, loss = 0.17427404\n",
      "Validation score: -0.000027\n",
      "Iteration 28, loss = 0.17425823\n",
      "Validation score: -0.000126\n",
      "Iteration 29, loss = 0.17425838\n",
      "Validation score: -0.000098\n",
      "Iteration 30, loss = 0.17425701\n",
      "Validation score: -0.000087\n",
      "Iteration 31, loss = 0.17425670\n",
      "Validation score: -0.000059\n",
      "Iteration 32, loss = 0.17425854\n",
      "Validation score: -0.000237\n",
      "Iteration 33, loss = 0.17425852\n",
      "Validation score: -0.000106\n",
      "Iteration 34, loss = 0.17425657\n",
      "Validation score: -0.000244\n",
      "Iteration 35, loss = 0.17425509\n",
      "Validation score: -0.000140\n",
      "Iteration 36, loss = 0.17425522\n",
      "Validation score: -0.000136\n",
      "Iteration 37, loss = 0.17425521\n",
      "Validation score: -0.000115\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 38, loss = 0.17425393\n",
      "Validation score: -0.000029\n",
      "Iteration 39, loss = 0.17425322\n",
      "Validation score: -0.000051\n",
      "Iteration 40, loss = 0.17425285\n",
      "Validation score: -0.000071\n",
      "Iteration 41, loss = 0.17425257\n",
      "Validation score: -0.000067\n",
      "Iteration 42, loss = 0.17425213\n",
      "Validation score: -0.000092\n",
      "Iteration 43, loss = 0.17425223\n",
      "Validation score: -0.000113\n",
      "Iteration 44, loss = 0.17425237\n",
      "Validation score: -0.000106\n",
      "Iteration 45, loss = 0.17425265\n",
      "Validation score: -0.000121\n",
      "Iteration 46, loss = 0.17425167\n",
      "Validation score: -0.000126\n",
      "Iteration 47, loss = 0.17425221\n",
      "Validation score: -0.000112\n",
      "Iteration 48, loss = 0.17425190\n",
      "Validation score: -0.000142\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000160\n",
      "Iteration 49, loss = 0.17425135\n",
      "Validation score: -0.000127\n",
      "Iteration 50, loss = 0.17425130\n",
      "Validation score: -0.000126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 42283622137448665972736.00000000\n",
      "Validation score: -4939207132287249.000000\n",
      "Iteration 2, loss = 111575334737938648924160.00000000\n",
      "Validation score: -31964570087.553642\n",
      "Iteration 3, loss = 113153744809747560792064.00000000\n",
      "Validation score: -658689.510495\n",
      "Iteration 4, loss = 113158287392961592295424.00000000\n",
      "Validation score: -272.440553\n",
      "Iteration 5, loss = 113152723762169249792000.00000000\n",
      "Validation score: -0.018990\n",
      "Iteration 6, loss = 113147096103297092681728.00000000\n",
      "Validation score: -0.006882\n",
      "Iteration 7, loss = 113141468315186936938496.00000000\n",
      "Validation score: -0.000945\n",
      "Iteration 8, loss = 113135840804392551841792.00000000\n",
      "Validation score: -0.000014\n",
      "Iteration 9, loss = 113130213573486656356352.00000000\n",
      "Validation score: -0.000038\n",
      "Iteration 10, loss = 113124586622471850950656.00000000\n",
      "Validation score: -0.000028\n",
      "Iteration 11, loss = 113118959951334344753152.00000000\n",
      "Validation score: -0.000072\n",
      "Iteration 12, loss = 113113333560060195897344.00000000\n",
      "Validation score: -0.000867\n",
      "Iteration 13, loss = 113107707448635512848384.00000000\n",
      "Validation score: -0.001620\n",
      "Iteration 14, loss = 113102081617046320185344.00000000\n",
      "Validation score: -0.003006\n",
      "Iteration 15, loss = 113096456065278759927808.00000000\n",
      "Validation score: -0.000003\n",
      "Iteration 16, loss = 113090830793318923763712.00000000\n",
      "Validation score: -0.000143\n",
      "Iteration 17, loss = 113085205801152769163264.00000000\n",
      "Validation score: -0.000362\n",
      "Iteration 18, loss = 113079581088766639472640.00000000\n",
      "Validation score: -0.000428\n",
      "Iteration 19, loss = 113073956656146290835456.00000000\n",
      "Validation score: -0.000489\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 20, loss = 113069877182783580798976.00000000\n",
      "Validation score: -0.000233\n",
      "Iteration 21, loss = 113068575278449171628032.00000000\n",
      "Validation score: -0.000008\n",
      "Iteration 22, loss = 113067449356243647332352.00000000\n",
      "Validation score: -0.000113\n",
      "Iteration 23, loss = 113066324564873517727744.00000000\n",
      "Validation score: -0.000137\n",
      "Iteration 24, loss = 113065199791816575025152.00000000\n",
      "Validation score: -0.000461\n",
      "Iteration 25, loss = 113064075029994075586560.00000000\n",
      "Validation score: -0.000168\n",
      "Iteration 26, loss = 113062950279360788037632.00000000\n",
      "Validation score: -0.000124\n",
      "Iteration 27, loss = 113061825539916443942912.00000000\n",
      "Validation score: -0.000140\n",
      "Iteration 28, loss = 113060700811660992970752.00000000\n",
      "Validation score: -0.000349\n",
      "Iteration 29, loss = 113059576094594183462912.00000000\n",
      "Validation score: -0.000492\n",
      "Iteration 30, loss = 113058451388715931533312.00000000\n",
      "Validation score: -0.000233\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 31, loss = 113057635598797859979264.00000000\n",
      "Validation score: -0.000000\n",
      "Iteration 32, loss = 113057375245540349968384.00000000\n",
      "Validation score: -0.000016\n",
      "Iteration 33, loss = 113057150082673302044672.00000000\n",
      "Validation score: -0.000000\n",
      "Iteration 34, loss = 113056925144156269969408.00000000\n",
      "Validation score: -0.000056\n",
      "Iteration 35, loss = 113056700207511508090880.00000000\n",
      "Validation score: -0.000025\n",
      "Iteration 36, loss = 113056475271323287814144.00000000\n",
      "Validation score: -0.000001\n",
      "Iteration 37, loss = 113056250335582633328640.00000000\n",
      "Validation score: -0.000001\n",
      "Iteration 38, loss = 113056025400289494302720.00000000\n",
      "Validation score: -0.000022\n",
      "Iteration 39, loss = 113055800465443954622464.00000000\n",
      "Validation score: -0.000018\n",
      "Iteration 40, loss = 113055575531045997510656.00000000\n",
      "Validation score: -0.000077\n",
      "Iteration 41, loss = 113055350597095505526784.00000000\n",
      "Validation score: -0.000053\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 42, loss = 113055187443301725765632.00000000\n",
      "Validation score: -0.000182\n",
      "Iteration 43, loss = 113055135373754500120576.00000000\n",
      "Validation score: -0.000124\n",
      "Iteration 44, loss = 113055090342044066906112.00000000\n",
      "Validation score: -0.000088\n",
      "Iteration 45, loss = 113055045355130880786432.00000000\n",
      "Validation score: -0.000076\n",
      "Iteration 46, loss = 113055000368520540192768.00000000\n",
      "Validation score: -0.000051\n",
      "Iteration 47, loss = 113054955381929946382336.00000000\n",
      "Validation score: -0.000053\n",
      "Iteration 48, loss = 113054910395357253861376.00000000\n",
      "Validation score: -0.000036\n",
      "Iteration 49, loss = 113054865408802378743808.00000000\n",
      "Validation score: -0.000047\n",
      "Iteration 50, loss = 113054820422265404915712.00000000\n",
      "Validation score: -0.000032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 189.43771407\n",
      "Validation score: -0.585921\n",
      "Iteration 2, loss = 12.23332508\n",
      "Validation score: -0.001780\n",
      "Iteration 3, loss = 12.29553414\n",
      "Validation score: -0.000993\n",
      "Iteration 4, loss = 12.29550351\n",
      "Validation score: -0.008705\n",
      "Iteration 5, loss = 12.29488534\n",
      "Validation score: -0.000348\n",
      "Iteration 6, loss = 12.29428851\n",
      "Validation score: -0.003115\n",
      "Iteration 7, loss = 12.29369386\n",
      "Validation score: -0.001938\n",
      "Iteration 8, loss = 12.29307359\n",
      "Validation score: -0.000501\n",
      "Iteration 9, loss = 12.29253026\n",
      "Validation score: -0.000034\n",
      "Iteration 10, loss = 12.29196129\n",
      "Validation score: -0.005705\n",
      "Iteration 11, loss = 12.29134816\n",
      "Validation score: 0.000001\n",
      "Iteration 12, loss = 12.29077336\n",
      "Validation score: -0.000072\n",
      "Iteration 13, loss = 12.29025460\n",
      "Validation score: -0.000264\n",
      "Iteration 14, loss = 12.28957721\n",
      "Validation score: -0.002797\n",
      "Iteration 15, loss = 12.28902409\n",
      "Validation score: -0.000148\n",
      "Iteration 16, loss = 12.28839708\n",
      "Validation score: -0.000528\n",
      "Iteration 17, loss = 12.28781079\n",
      "Validation score: -0.005181\n",
      "Iteration 18, loss = 12.28729356\n",
      "Validation score: -0.000204\n",
      "Iteration 19, loss = 12.28661071\n",
      "Validation score: -0.015085\n",
      "Iteration 20, loss = 12.28608483\n",
      "Validation score: -0.010181\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 21, loss = 12.28575416\n",
      "Validation score: -0.000422\n",
      "Iteration 22, loss = 12.28547496\n",
      "Validation score: -0.000303\n",
      "Iteration 23, loss = 12.28537547\n",
      "Validation score: -0.002710\n",
      "Iteration 24, loss = 12.28525567\n",
      "Validation score: -0.003998\n",
      "Iteration 25, loss = 12.28513046\n",
      "Validation score: -0.000824\n",
      "Iteration 26, loss = 12.28502288\n",
      "Validation score: -0.006502\n",
      "Iteration 27, loss = 12.28489412\n",
      "Validation score: -0.001279\n",
      "Iteration 28, loss = 12.28477539\n",
      "Validation score: -0.000676\n",
      "Iteration 29, loss = 12.28466046\n",
      "Validation score: -0.000811\n",
      "Iteration 30, loss = 12.28454293\n",
      "Validation score: -0.001390\n",
      "Iteration 31, loss = 12.28442288\n",
      "Validation score: -0.002131\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 32, loss = 12.28433093\n",
      "Validation score: -0.000786\n",
      "Iteration 33, loss = 12.28430176\n",
      "Validation score: -0.000597\n",
      "Iteration 34, loss = 12.28427401\n",
      "Validation score: -0.000695\n",
      "Iteration 35, loss = 12.28425179\n",
      "Validation score: -0.000946\n",
      "Iteration 36, loss = 12.28422968\n",
      "Validation score: -0.001059\n",
      "Iteration 37, loss = 12.28421059\n",
      "Validation score: -0.000788\n",
      "Iteration 38, loss = 12.28418148\n",
      "Validation score: -0.000672\n",
      "Iteration 39, loss = 12.28416117\n",
      "Validation score: -0.000523\n",
      "Iteration 40, loss = 12.28413604\n",
      "Validation score: -0.000829\n",
      "Iteration 41, loss = 12.28411037\n",
      "Validation score: -0.000811\n",
      "Iteration 42, loss = 12.28408618\n",
      "Validation score: -0.000899\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 43, loss = 12.28406937\n",
      "Validation score: -0.000949\n",
      "Iteration 44, loss = 12.28406299\n",
      "Validation score: -0.000862\n",
      "Iteration 45, loss = 12.28405886\n",
      "Validation score: -0.000931\n",
      "Iteration 46, loss = 12.28405312\n",
      "Validation score: -0.000903\n",
      "Iteration 47, loss = 12.28404941\n",
      "Validation score: -0.000863\n",
      "Iteration 48, loss = 12.28404355\n",
      "Validation score: -0.000869\n",
      "Iteration 49, loss = 12.28403898\n",
      "Validation score: -0.000859\n",
      "Iteration 50, loss = 12.28403445\n",
      "Validation score: -0.000864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 30.09086589\n",
      "Validation score: -0.211650\n",
      "Iteration 2, loss = 0.89556713\n",
      "Validation score: -0.000076\n",
      "Iteration 3, loss = 0.89793932\n",
      "Validation score: -0.002185\n",
      "Iteration 4, loss = 0.89787250\n",
      "Validation score: -0.002630\n",
      "Iteration 5, loss = 0.89782861\n",
      "Validation score: -0.000023\n",
      "Iteration 6, loss = 0.89777614\n",
      "Validation score: -0.001161\n",
      "Iteration 7, loss = 0.89771673\n",
      "Validation score: -0.000268\n",
      "Iteration 8, loss = 0.89770357\n",
      "Validation score: -0.003559\n",
      "Iteration 9, loss = 0.89764443\n",
      "Validation score: -0.008746\n",
      "Iteration 10, loss = 0.89764236\n",
      "Validation score: -0.000611\n",
      "Iteration 11, loss = 0.89758129\n",
      "Validation score: -0.002186\n",
      "Iteration 12, loss = 0.89756037\n",
      "Validation score: -0.000840\n",
      "Iteration 13, loss = 0.89750296\n",
      "Validation score: -0.000003\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 14, loss = 0.89745165\n",
      "Validation score: -0.002677\n",
      "Iteration 15, loss = 0.89742135\n",
      "Validation score: -0.000363\n",
      "Iteration 16, loss = 0.89740676\n",
      "Validation score: -0.001363\n",
      "Iteration 17, loss = 0.89739568\n",
      "Validation score: -0.002239\n",
      "Iteration 18, loss = 0.89739884\n",
      "Validation score: -0.001850\n",
      "Iteration 19, loss = 0.89739348\n",
      "Validation score: -0.000610\n",
      "Iteration 20, loss = 0.89736989\n",
      "Validation score: -0.002377\n",
      "Iteration 21, loss = 0.89737728\n",
      "Validation score: -0.000438\n",
      "Iteration 22, loss = 0.89736934\n",
      "Validation score: -0.000724\n",
      "Iteration 23, loss = 0.89735459\n",
      "Validation score: -0.002984\n",
      "Iteration 24, loss = 0.89735891\n",
      "Validation score: -0.002697\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 25, loss = 0.89732657\n",
      "Validation score: -0.000665\n",
      "Iteration 26, loss = 0.89732869\n",
      "Validation score: -0.000652\n",
      "Iteration 27, loss = 0.89732772\n",
      "Validation score: -0.000975\n",
      "Iteration 28, loss = 0.89732914\n",
      "Validation score: -0.001154\n",
      "Iteration 29, loss = 0.89732348\n",
      "Validation score: -0.000707\n",
      "Iteration 30, loss = 0.89732643\n",
      "Validation score: -0.000786\n",
      "Iteration 31, loss = 0.89732119\n",
      "Validation score: -0.000898\n",
      "Iteration 32, loss = 0.89731961\n",
      "Validation score: -0.000795\n",
      "Iteration 33, loss = 0.89731500\n",
      "Validation score: -0.001094\n",
      "Iteration 34, loss = 0.89731481\n",
      "Validation score: -0.000727\n",
      "Iteration 35, loss = 0.89731109\n",
      "Validation score: -0.000913\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 36, loss = 0.89730870\n",
      "Validation score: -0.000600\n",
      "Iteration 37, loss = 0.89730740\n",
      "Validation score: -0.000682\n",
      "Iteration 38, loss = 0.89730679\n",
      "Validation score: -0.000743\n",
      "Iteration 39, loss = 0.89730659\n",
      "Validation score: -0.000808\n",
      "Iteration 40, loss = 0.89730769\n",
      "Validation score: -0.000783\n",
      "Iteration 41, loss = 0.89730596\n",
      "Validation score: -0.000860\n",
      "Iteration 42, loss = 0.89730735\n",
      "Validation score: -0.000905\n",
      "Iteration 43, loss = 0.89730684\n",
      "Validation score: -0.000953\n",
      "Iteration 44, loss = 0.89730458\n",
      "Validation score: -0.000770\n",
      "Iteration 45, loss = 0.89730474\n",
      "Validation score: -0.000883\n",
      "Iteration 46, loss = 0.89730512\n",
      "Validation score: -0.000836\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000160\n",
      "Iteration 47, loss = 0.89730347\n",
      "Validation score: -0.000826\n",
      "Iteration 48, loss = 0.89730340\n",
      "Validation score: -0.000844\n",
      "Iteration 49, loss = 0.89730320\n",
      "Validation score: -0.000824\n",
      "Iteration 50, loss = 0.89730322\n",
      "Validation score: -0.000846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 59.94040040\n",
      "Validation score: -0.545901\n",
      "Iteration 2, loss = 2.60548688\n",
      "Validation score: -0.001744\n",
      "Iteration 3, loss = 2.61193316\n",
      "Validation score: -0.000624\n",
      "Iteration 4, loss = 2.61185378\n",
      "Validation score: -0.000501\n",
      "Iteration 5, loss = 2.61179130\n",
      "Validation score: -0.003313\n",
      "Iteration 6, loss = 2.61169656\n",
      "Validation score: -0.003900\n",
      "Iteration 7, loss = 2.61150578\n",
      "Validation score: -0.000119\n",
      "Iteration 8, loss = 2.61139433\n",
      "Validation score: -0.002041\n",
      "Iteration 9, loss = 2.61125741\n",
      "Validation score: -0.002479\n",
      "Iteration 10, loss = 2.61116431\n",
      "Validation score: -0.000650\n",
      "Iteration 11, loss = 2.61104080\n",
      "Validation score: -0.000435\n",
      "Iteration 12, loss = 2.61087337\n",
      "Validation score: -0.007146\n",
      "Iteration 13, loss = 2.61082363\n",
      "Validation score: -0.001902\n",
      "Iteration 14, loss = 2.61065756\n",
      "Validation score: -0.000603\n",
      "Iteration 15, loss = 2.61051085\n",
      "Validation score: -0.000090\n",
      "Iteration 16, loss = 2.61042556\n",
      "Validation score: -0.000873\n",
      "Iteration 17, loss = 2.61027608\n",
      "Validation score: -0.000141\n",
      "Iteration 18, loss = 2.61014417\n",
      "Validation score: -0.000617\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 19, loss = 2.61006998\n",
      "Validation score: -0.000057\n",
      "Iteration 20, loss = 2.61001538\n",
      "Validation score: -0.000004\n",
      "Iteration 21, loss = 2.60997586\n",
      "Validation score: -0.000956\n",
      "Iteration 22, loss = 2.60996206\n",
      "Validation score: -0.000147\n",
      "Iteration 23, loss = 2.60992665\n",
      "Validation score: -0.000001\n",
      "Iteration 24, loss = 2.60990918\n",
      "Validation score: -0.000107\n",
      "Iteration 25, loss = 2.60988267\n",
      "Validation score: -0.000271\n",
      "Iteration 26, loss = 2.60985912\n",
      "Validation score: -0.000099\n",
      "Iteration 27, loss = 2.60983349\n",
      "Validation score: -0.000203\n",
      "Iteration 28, loss = 2.60981411\n",
      "Validation score: -0.000130\n",
      "Iteration 29, loss = 2.60978196\n",
      "Validation score: -0.001420\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 30, loss = 2.60978165\n",
      "Validation score: -0.000190\n",
      "Iteration 31, loss = 2.60975671\n",
      "Validation score: -0.000009\n",
      "Iteration 32, loss = 2.60974933\n",
      "Validation score: -0.000031\n",
      "Iteration 33, loss = 2.60974499\n",
      "Validation score: -0.000018\n",
      "Iteration 34, loss = 2.60974073\n",
      "Validation score: -0.000040\n",
      "Iteration 35, loss = 2.60973758\n",
      "Validation score: -0.000046\n",
      "Iteration 36, loss = 2.60973355\n",
      "Validation score: -0.000004\n",
      "Iteration 37, loss = 2.60972272\n",
      "Validation score: -0.000020\n",
      "Iteration 38, loss = 2.60972443\n",
      "Validation score: -0.000009\n",
      "Iteration 39, loss = 2.60971754\n",
      "Validation score: -0.000003\n",
      "Iteration 40, loss = 2.60970876\n",
      "Validation score: -0.000012\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 41, loss = 2.60970332\n",
      "Validation score: -0.000112\n",
      "Iteration 42, loss = 2.60970334\n",
      "Validation score: -0.000057\n",
      "Iteration 43, loss = 2.60970199\n",
      "Validation score: -0.000033\n",
      "Iteration 44, loss = 2.60970049\n",
      "Validation score: -0.000032\n",
      "Iteration 45, loss = 2.60969932\n",
      "Validation score: -0.000025\n",
      "Iteration 46, loss = 2.60969862\n",
      "Validation score: -0.000016\n",
      "Iteration 47, loss = 2.60969767\n",
      "Validation score: -0.000009\n",
      "Iteration 48, loss = 2.60969721\n",
      "Validation score: -0.000019\n",
      "Iteration 49, loss = 2.60969575\n",
      "Validation score: -0.000008\n",
      "Iteration 50, loss = 2.60969488\n",
      "Validation score: -0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 117373955967083488304177348608.00000000\n",
      "Validation score: -37330334622258413568.000000\n",
      "Iteration 2, loss = 231046737382702015763332464640.00000000\n",
      "Validation score: -3310033934305870.500000\n",
      "Iteration 3, loss = 233087996508649434758414073856.00000000\n",
      "Validation score: -97545666762.282440\n",
      "Iteration 4, loss = 233094148966034877614286438400.00000000\n",
      "Validation score: -27184193.809245\n",
      "Iteration 5, loss = 233082442766948552263428210688.00000000\n",
      "Validation score: -98.238367\n",
      "Iteration 6, loss = 233070581289695521045066285056.00000000\n",
      "Validation score: -0.207872\n",
      "Iteration 7, loss = 233058719055679035725968310272.00000000\n",
      "Validation score: -0.002177\n",
      "Iteration 8, loss = 233046857413523009792366346240.00000000\n",
      "Validation score: -0.000737\n",
      "Iteration 9, loss = 233034996374967412679140966400.00000000\n",
      "Validation score: -0.004303\n",
      "Iteration 10, loss = 233023135940084689008423075840.00000000\n",
      "Validation score: -0.000109\n",
      "Iteration 11, loss = 233011276108844720957704634368.00000000\n",
      "Validation score: 0.000001\n",
      "Iteration 12, loss = 232999416881217074045128802304.00000000\n",
      "Validation score: -0.000072\n",
      "Iteration 13, loss = 232987558257170891576373673984.00000000\n",
      "Validation score: -0.014621\n",
      "Iteration 14, loss = 232975700236675527963349876736.00000000\n",
      "Validation score: -0.007338\n",
      "Iteration 15, loss = 232963842819699880221130883072.00000000\n",
      "Validation score: -0.000018\n",
      "Iteration 16, loss = 232951986006213549052231942144.00000000\n",
      "Validation score: -0.000563\n",
      "Iteration 17, loss = 232940129796185712946703237120.00000000\n",
      "Validation score: -0.005293\n",
      "Iteration 18, loss = 232928274189585831869571661824.00000000\n",
      "Validation score: -0.004148\n",
      "Iteration 19, loss = 232916419186383189864003665920.00000000\n",
      "Validation score: -0.005782\n",
      "Iteration 20, loss = 232904564786546930235677343744.00000000\n",
      "Validation score: -0.012307\n",
      "Iteration 21, loss = 232892710990046442580875411456.00000000\n",
      "Validation score: -0.004790\n",
      "Iteration 22, loss = 232880857796850905389648052224.00000000\n",
      "Validation score: -0.006219\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 23, loss = 232871927126534943611736293376.00000000\n",
      "Validation score: -0.000110\n",
      "Iteration 24, loss = 232869031143385283003821326336.00000000\n",
      "Validation score: -0.000869\n",
      "Iteration 25, loss = 232866656120268489410136244224.00000000\n",
      "Validation score: -0.000857\n",
      "Iteration 26, loss = 232864285667982043586752413696.00000000\n",
      "Validation score: -0.000188\n",
      "Iteration 27, loss = 232861915279508015677255450624.00000000\n",
      "Validation score: 0.000000\n",
      "Iteration 28, loss = 232859544915509362892656869376.00000000\n",
      "Validation score: -0.000195\n",
      "Iteration 29, loss = 232857174575642193180160425984.00000000\n",
      "Validation score: -0.000284\n",
      "Iteration 30, loss = 232854804259903410315022303232.00000000\n",
      "Validation score: -0.000530\n",
      "Iteration 31, loss = 232852433968292592084777435136.00000000\n",
      "Validation score: -0.000113\n",
      "Iteration 32, loss = 232850063700809668120681644032.00000000\n",
      "Validation score: -0.000746\n",
      "Iteration 33, loss = 232847693457454427316502396928.00000000\n",
      "Validation score: -0.000317\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 34, loss = 232845907560852455107665592320.00000000\n",
      "Validation score: -0.000196\n",
      "Iteration 35, loss = 232845328427890297946312278016.00000000\n",
      "Validation score: -0.000148\n",
      "Iteration 36, loss = 232844853470074686779059863552.00000000\n",
      "Validation score: -0.000196\n",
      "Iteration 37, loss = 232844379422452182164592132096.00000000\n",
      "Validation score: -0.000150\n",
      "Iteration 38, loss = 232843905383730725554273386496.00000000\n",
      "Validation score: -0.000270\n",
      "Iteration 39, loss = 232843431346043302455273324544.00000000\n",
      "Validation score: -0.000198\n",
      "Iteration 40, loss = 232842957309321549632623345664.00000000\n",
      "Validation score: -0.000232\n",
      "Iteration 41, loss = 232842483273565150426974650368.00000000\n",
      "Validation score: -0.000220\n",
      "Iteration 42, loss = 232842009238773612257117995008.00000000\n",
      "Validation score: -0.000148\n",
      "Iteration 43, loss = 232841535204947075860541734912.00000000\n",
      "Validation score: -0.000072\n",
      "Iteration 44, loss = 232841061172085646790362136576.00000000\n",
      "Validation score: -0.000057\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 45, loss = 232840704002262949897751756800.00000000\n",
      "Validation score: 0.000000\n",
      "Iteration 46, loss = 232840588178217071837903323136.00000000\n",
      "Validation score: -0.000025\n",
      "Iteration 47, loss = 232840493188526264854536781824.00000000\n",
      "Validation score: -0.000064\n",
      "Iteration 48, loss = 232840398380715088041132163072.00000000\n",
      "Validation score: -0.000078\n",
      "Iteration 49, loss = 232840303574529605140092026880.00000000\n",
      "Validation score: -0.000123\n",
      "Iteration 50, loss = 232840208768396582137836339200.00000000\n",
      "Validation score: -0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 169.16615988\n",
      "Validation score: -13.247065\n",
      "Iteration 2, loss = 12.32682703\n",
      "Validation score: -0.000374\n",
      "Iteration 3, loss = 12.33160956\n",
      "Validation score: -0.002597\n",
      "Iteration 4, loss = 12.33137477\n",
      "Validation score: -0.000720\n",
      "Iteration 5, loss = 12.33075746\n",
      "Validation score: -0.000745\n",
      "Iteration 6, loss = 12.33011757\n",
      "Validation score: -0.010338\n",
      "Iteration 7, loss = 12.32952633\n",
      "Validation score: -0.003846\n",
      "Iteration 8, loss = 12.32894421\n",
      "Validation score: -0.000005\n",
      "Iteration 9, loss = 12.32831099\n",
      "Validation score: -0.000632\n",
      "Iteration 10, loss = 12.32771182\n",
      "Validation score: -0.001069\n",
      "Iteration 11, loss = 12.32711665\n",
      "Validation score: -0.001560\n",
      "Iteration 12, loss = 12.32653614\n",
      "Validation score: -0.000668\n",
      "Iteration 13, loss = 12.32593942\n",
      "Validation score: -0.003106\n",
      "Iteration 14, loss = 12.32532108\n",
      "Validation score: -0.000171\n",
      "Iteration 15, loss = 12.32472307\n",
      "Validation score: -0.004053\n",
      "Iteration 16, loss = 12.32412384\n",
      "Validation score: -0.000962\n",
      "Iteration 17, loss = 12.32356579\n",
      "Validation score: -0.005277\n",
      "Iteration 18, loss = 12.32292131\n",
      "Validation score: -0.001178\n",
      "Iteration 19, loss = 12.32232705\n",
      "Validation score: -0.004940\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 20, loss = 12.32187225\n",
      "Validation score: -0.000047\n",
      "Iteration 21, loss = 12.32172589\n",
      "Validation score: -0.000582\n",
      "Iteration 22, loss = 12.32158428\n",
      "Validation score: -0.000105\n",
      "Iteration 23, loss = 12.32146256\n",
      "Validation score: -0.000015\n",
      "Iteration 24, loss = 12.32134439\n",
      "Validation score: -0.000619\n",
      "Iteration 25, loss = 12.32123014\n",
      "Validation score: -0.000088\n",
      "Iteration 26, loss = 12.32110862\n",
      "Validation score: -0.001211\n",
      "Iteration 27, loss = 12.32098929\n",
      "Validation score: -0.001013\n",
      "Iteration 28, loss = 12.32086871\n",
      "Validation score: -0.000065\n",
      "Iteration 29, loss = 12.32074814\n",
      "Validation score: -0.000523\n",
      "Iteration 30, loss = 12.32062779\n",
      "Validation score: -0.000053\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 31, loss = 12.32054872\n",
      "Validation score: 0.000001\n",
      "Iteration 32, loss = 12.32049997\n",
      "Validation score: -0.000114\n",
      "Iteration 33, loss = 12.32047475\n",
      "Validation score: -0.000221\n",
      "Iteration 34, loss = 12.32045123\n",
      "Validation score: -0.000154\n",
      "Iteration 35, loss = 12.32042786\n",
      "Validation score: -0.000026\n",
      "Iteration 36, loss = 12.32041048\n",
      "Validation score: -0.000090\n",
      "Iteration 37, loss = 12.32038988\n",
      "Validation score: -0.000022\n",
      "Iteration 38, loss = 12.32035712\n",
      "Validation score: -0.000039\n",
      "Iteration 39, loss = 12.32033284\n",
      "Validation score: -0.000050\n",
      "Iteration 40, loss = 12.32030740\n",
      "Validation score: -0.000081\n",
      "Iteration 41, loss = 12.32028486\n",
      "Validation score: -0.000148\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 42, loss = 12.32026710\n",
      "Validation score: -0.000458\n",
      "Iteration 43, loss = 12.32026100\n",
      "Validation score: -0.000305\n",
      "Iteration 44, loss = 12.32025447\n",
      "Validation score: -0.000239\n",
      "Iteration 45, loss = 12.32024974\n",
      "Validation score: -0.000174\n",
      "Iteration 46, loss = 12.32024476\n",
      "Validation score: -0.000212\n",
      "Iteration 47, loss = 12.32023994\n",
      "Validation score: -0.000176\n",
      "Iteration 48, loss = 12.32023466\n",
      "Validation score: -0.000164\n",
      "Iteration 49, loss = 12.32022990\n",
      "Validation score: -0.000161\n",
      "Iteration 50, loss = 12.32022551\n",
      "Validation score: -0.000113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 550193.63865459\n",
      "Validation score: -1122.175588\n",
      "Iteration 2, loss = 549579.63951029\n",
      "Validation score: -0.002250\n",
      "Iteration 3, loss = 552085.17689900\n",
      "Validation score: -0.004717\n",
      "Iteration 4, loss = 552075.53831483\n",
      "Validation score: -0.000043\n",
      "Iteration 5, loss = 552046.05205927\n",
      "Validation score: -0.016072\n",
      "Iteration 6, loss = 552016.41149549\n",
      "Validation score: -0.009189\n",
      "Iteration 7, loss = 551986.77125557\n",
      "Validation score: -0.002344\n",
      "Iteration 8, loss = 551957.13257513\n",
      "Validation score: -0.007729\n",
      "Iteration 9, loss = 551927.49553211\n",
      "Validation score: -0.001631\n",
      "Iteration 10, loss = 551897.86012505\n",
      "Validation score: -0.000002\n",
      "Iteration 11, loss = 551868.22618795\n",
      "Validation score: -0.006318\n",
      "Iteration 12, loss = 551838.59389612\n",
      "Validation score: -0.001808\n",
      "Iteration 13, loss = 551808.96320939\n",
      "Validation score: -0.005047\n",
      "Iteration 14, loss = 551779.33418738\n",
      "Validation score: -0.014277\n",
      "Iteration 15, loss = 551749.70660627\n",
      "Validation score: -0.004531\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 16, loss = 551727.20759891\n",
      "Validation score: -0.002072\n",
      "Iteration 17, loss = 551719.92406105\n",
      "Validation score: -0.000111\n",
      "Iteration 18, loss = 551713.98842935\n",
      "Validation score: -0.004944\n",
      "Iteration 19, loss = 551708.06346097\n",
      "Validation score: -0.002302\n",
      "Iteration 20, loss = 551702.13861929\n",
      "Validation score: -0.001407\n",
      "Iteration 21, loss = 551696.21385142\n",
      "Validation score: -0.004924\n",
      "Iteration 22, loss = 551690.28914278\n",
      "Validation score: -0.002117\n",
      "Iteration 23, loss = 551684.36446350\n",
      "Validation score: -0.005848\n",
      "Iteration 24, loss = 551678.43990138\n",
      "Validation score: -0.003299\n",
      "Iteration 25, loss = 551672.51536274\n",
      "Validation score: -0.002194\n",
      "Iteration 26, loss = 551666.59091957\n",
      "Validation score: -0.004002\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 27, loss = 551662.09177432\n",
      "Validation score: -0.004777\n",
      "Iteration 28, loss = 551660.63520003\n",
      "Validation score: -0.002069\n",
      "Iteration 29, loss = 551659.44819481\n",
      "Validation score: -0.002598\n",
      "Iteration 30, loss = 551658.26331755\n",
      "Validation score: -0.002663\n",
      "Iteration 31, loss = 551657.07845229\n",
      "Validation score: -0.002630\n",
      "Iteration 32, loss = 551655.89358728\n",
      "Validation score: -0.002590\n",
      "Iteration 33, loss = 551654.70872870\n",
      "Validation score: -0.002871\n",
      "Iteration 34, loss = 551653.52386793\n",
      "Validation score: -0.002125\n",
      "Iteration 35, loss = 551652.33901813\n",
      "Validation score: -0.002000\n",
      "Iteration 36, loss = 551651.15416014\n",
      "Validation score: -0.002260\n",
      "Iteration 37, loss = 551649.96931057\n",
      "Validation score: -0.003164\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 38, loss = 551649.06951745\n",
      "Validation score: -0.004588\n",
      "Iteration 39, loss = 551648.77820970\n",
      "Validation score: -0.003747\n",
      "Iteration 40, loss = 551648.54080742\n",
      "Validation score: -0.003204\n",
      "Iteration 41, loss = 551648.30383267\n",
      "Validation score: -0.002851\n",
      "Iteration 42, loss = 551648.06686264\n",
      "Validation score: -0.002593\n",
      "Iteration 43, loss = 551647.82989462\n",
      "Validation score: -0.002637\n",
      "Iteration 44, loss = 551647.59292576\n",
      "Validation score: -0.002418\n",
      "Iteration 45, loss = 551647.35595674\n",
      "Validation score: -0.002545\n",
      "Iteration 46, loss = 551647.11898855\n",
      "Validation score: -0.002458\n",
      "Iteration 47, loss = 551646.88202024\n",
      "Validation score: -0.002388\n",
      "Iteration 48, loss = 551646.64505380\n",
      "Validation score: -0.002483\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000160\n",
      "Iteration 49, loss = 551646.46509111\n",
      "Validation score: -0.002209\n",
      "Iteration 50, loss = 551646.40683127\n",
      "Validation score: -0.002212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for cluster in range(clusters):\n",
    "    print('Cluster:',cluster)\n",
    "    #compute the mean (HasDetection) of cluster\n",
    "    #mean =np.mean(Y_test.loc[test['Cluster'] == cluster])  #test measure\n",
    "    y=y_train.loc[train['Cluster'] == cluster] # y train \n",
    "    X_train=train.loc[train['Cluster'] == cluster] # train\n",
    "    X_test=test.loc[test['Cluster'] == cluster] # train measure\n",
    "    \n",
    "    model.fit(X_train, y)\n",
    "    pred=list(model.predict(X_test))\n",
    "    \n",
    "    '''Update predict in cluster'''\n",
    "    for val in range(np.shape(pred_test)[0]):\n",
    "        if test['Cluster'][val] == cluster:\n",
    "            pred_test[val]=pred.pop(0)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "   \n",
    "submission['target'] = pred_test\n",
    "submission.to_csv('./output/submission.csv',index=False)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
