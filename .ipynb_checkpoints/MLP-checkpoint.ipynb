{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load file and libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "#import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Loading files\"\"\"\n",
    "train=pd.read_csv('./input/train.csv')\n",
    "test=pd.read_csv('./input/test.csv')\n",
    "\n",
    "\"\"\"Dealing with labels\"\"\"\n",
    "submission=pd.DataFrame()\n",
    "y_train=train['target']\n",
    "submission['ID_code']=test['ID_code']\n",
    "train.drop(columns=['target','ID_code'],inplace=True)\n",
    "test.drop(columns=['ID_code'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7   var_8  \\\n",
       "0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266 -4.9200   \n",
       "1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338  3.1468   \n",
       "2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155 -4.9193   \n",
       "3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250 -5.8609   \n",
       "4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514  6.2654   \n",
       "\n",
       "    var_9   ...     var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  5.7470   ...      4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  8.0851   ...      7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  5.9525   ...      2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  8.2450   ...      4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  7.6784   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>8.8100</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>5.9739</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>8.3442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>7.4578</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>7.1437</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0    var_1    var_2   var_3    var_4   var_5   var_6    var_7  \\\n",
       "0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493  18.2675   \n",
       "1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196  18.6316   \n",
       "2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950  20.2537   \n",
       "3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397  20.5660   \n",
       "4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595  10.6048   \n",
       "\n",
       "    var_8   var_9   ...     var_190  var_191  var_192  var_193  var_194  \\\n",
       "0  2.1337  8.8100   ...     -2.1556  11.8495  -1.4300   2.4508  13.7112   \n",
       "1 -4.4131  5.9739   ...     10.6165   8.8349   0.9403  10.1282  15.5765   \n",
       "2  1.5233  8.3442   ...     -0.7484  10.9935   1.9803   2.1800  12.9813   \n",
       "3  3.3755  7.4578   ...      9.5702   9.0766   1.6580   3.5813  15.1874   \n",
       "4  2.9890  7.1437   ...      4.2259   9.1723   1.2835   3.3778  19.5542   \n",
       "\n",
       "   var_195  var_196  var_197  var_198  var_199  \n",
       "0   2.4669   4.3654  10.7200  15.4722  -8.7197  \n",
       "1   0.4773  -1.4852   9.8714  19.1293 -20.9760  \n",
       "2   2.1281  -7.1086   7.0618  19.8956 -23.1794  \n",
       "3   3.1656   3.9567   9.2295  13.0168  -4.2108  \n",
       "4  -0.2860  -5.1612   7.2882  13.9260  -9.1846  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_float(data, usecols):\n",
    "    for col in usecols:\n",
    "        try:\n",
    "            data[col] = data[col].astype(np.float32)\n",
    "        except:\n",
    "            print(f'{col} cannot be casted to number')\n",
    "    return data\n",
    "\n",
    "#'''\n",
    "columns=train.columns\n",
    "#train = convert_to_float(train, train.columns)\n",
    "#test = convert_to_float(test, test.columns)\n",
    "\n",
    "train = train.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "train = min_max_scaler.fit_transform(train)\n",
    "test=test.values\n",
    "test =  min_max_scaler.transform(test)\n",
    "train = pd.DataFrame(train)\n",
    "test = pd.DataFrame(test)\n",
    "train.columns=columns\n",
    "test.columns=columns\n",
    "\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.427853</td>\n",
       "      <td>0.324824</td>\n",
       "      <td>0.568059</td>\n",
       "      <td>0.388041</td>\n",
       "      <td>0.550670</td>\n",
       "      <td>0.467321</td>\n",
       "      <td>0.454298</td>\n",
       "      <td>0.594255</td>\n",
       "      <td>0.270395</td>\n",
       "      <td>0.247420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569515</td>\n",
       "      <td>0.342943</td>\n",
       "      <td>0.568958</td>\n",
       "      <td>0.448173</td>\n",
       "      <td>0.510975</td>\n",
       "      <td>0.300318</td>\n",
       "      <td>0.678981</td>\n",
       "      <td>0.430958</td>\n",
       "      <td>0.327658</td>\n",
       "      <td>0.560645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.557212</td>\n",
       "      <td>0.428639</td>\n",
       "      <td>0.681235</td>\n",
       "      <td>0.410417</td>\n",
       "      <td>0.628408</td>\n",
       "      <td>0.795072</td>\n",
       "      <td>0.536604</td>\n",
       "      <td>0.500584</td>\n",
       "      <td>0.660911</td>\n",
       "      <td>0.573056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668079</td>\n",
       "      <td>0.536531</td>\n",
       "      <td>0.523717</td>\n",
       "      <td>0.756190</td>\n",
       "      <td>0.350211</td>\n",
       "      <td>0.765154</td>\n",
       "      <td>0.686614</td>\n",
       "      <td>0.468277</td>\n",
       "      <td>0.609546</td>\n",
       "      <td>0.605827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.411969</td>\n",
       "      <td>0.483777</td>\n",
       "      <td>0.578061</td>\n",
       "      <td>0.599690</td>\n",
       "      <td>0.474941</td>\n",
       "      <td>0.471329</td>\n",
       "      <td>0.753295</td>\n",
       "      <td>0.414724</td>\n",
       "      <td>0.270429</td>\n",
       "      <td>0.276041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522496</td>\n",
       "      <td>0.643141</td>\n",
       "      <td>0.448960</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.671183</td>\n",
       "      <td>0.881350</td>\n",
       "      <td>0.236337</td>\n",
       "      <td>0.381950</td>\n",
       "      <td>0.425833</td>\n",
       "      <td>0.582736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.535099</td>\n",
       "      <td>0.507140</td>\n",
       "      <td>0.396562</td>\n",
       "      <td>0.546993</td>\n",
       "      <td>0.647586</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.572995</td>\n",
       "      <td>0.428577</td>\n",
       "      <td>0.224846</td>\n",
       "      <td>0.595326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570474</td>\n",
       "      <td>0.383085</td>\n",
       "      <td>0.370986</td>\n",
       "      <td>0.439205</td>\n",
       "      <td>0.745555</td>\n",
       "      <td>0.418549</td>\n",
       "      <td>0.346810</td>\n",
       "      <td>0.717176</td>\n",
       "      <td>0.590016</td>\n",
       "      <td>0.443232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.473637</td>\n",
       "      <td>0.533434</td>\n",
       "      <td>0.624133</td>\n",
       "      <td>0.504796</td>\n",
       "      <td>0.621079</td>\n",
       "      <td>0.702836</td>\n",
       "      <td>0.589011</td>\n",
       "      <td>0.622220</td>\n",
       "      <td>0.811883</td>\n",
       "      <td>0.516413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387371</td>\n",
       "      <td>0.629275</td>\n",
       "      <td>0.299888</td>\n",
       "      <td>0.697737</td>\n",
       "      <td>0.238801</td>\n",
       "      <td>0.393218</td>\n",
       "      <td>0.557507</td>\n",
       "      <td>0.586526</td>\n",
       "      <td>0.591416</td>\n",
       "      <td>0.446041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_0     var_1     var_2     var_3     var_4     var_5     var_6  \\\n",
       "0  0.427853  0.324824  0.568059  0.388041  0.550670  0.467321  0.454298   \n",
       "1  0.557212  0.428639  0.681235  0.410417  0.628408  0.795072  0.536604   \n",
       "2  0.411969  0.483777  0.578061  0.599690  0.474941  0.471329  0.753295   \n",
       "3  0.535099  0.507140  0.396562  0.546993  0.647586  0.616822  0.572995   \n",
       "4  0.473637  0.533434  0.624133  0.504796  0.621079  0.702836  0.589011   \n",
       "\n",
       "      var_7     var_8     var_9    ...      var_190   var_191   var_192  \\\n",
       "0  0.594255  0.270395  0.247420    ...     0.569515  0.342943  0.568958   \n",
       "1  0.500584  0.660911  0.573056    ...     0.668079  0.536531  0.523717   \n",
       "2  0.414724  0.270429  0.276041    ...     0.522496  0.643141  0.448960   \n",
       "3  0.428577  0.224846  0.595326    ...     0.570474  0.383085  0.370986   \n",
       "4  0.622220  0.811883  0.516413    ...     0.387371  0.629275  0.299888   \n",
       "\n",
       "    var_193   var_194   var_195   var_196   var_197   var_198   var_199  \n",
       "0  0.448173  0.510975  0.300318  0.678981  0.430958  0.327658  0.560645  \n",
       "1  0.756190  0.350211  0.765154  0.686614  0.468277  0.609546  0.605827  \n",
       "2  0.448000  0.671183  0.881350  0.236337  0.381950  0.425833  0.582736  \n",
       "3  0.439205  0.745555  0.418549  0.346810  0.717176  0.590016  0.443232  \n",
       "4  0.697737  0.238801  0.393218  0.557507  0.586526  0.591416  0.446041  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.535360</td>\n",
       "      <td>0.897837</td>\n",
       "      <td>0.628717</td>\n",
       "      <td>0.715833</td>\n",
       "      <td>0.548256</td>\n",
       "      <td>0.605894</td>\n",
       "      <td>0.574061</td>\n",
       "      <td>0.578182</td>\n",
       "      <td>0.611866</td>\n",
       "      <td>0.674016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366928</td>\n",
       "      <td>0.749230</td>\n",
       "      <td>0.195180</td>\n",
       "      <td>0.473444</td>\n",
       "      <td>0.260824</td>\n",
       "      <td>0.810571</td>\n",
       "      <td>0.570992</td>\n",
       "      <td>0.788006</td>\n",
       "      <td>0.463751</td>\n",
       "      <td>0.447387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.408005</td>\n",
       "      <td>0.641132</td>\n",
       "      <td>0.533050</td>\n",
       "      <td>0.395056</td>\n",
       "      <td>0.355501</td>\n",
       "      <td>0.573148</td>\n",
       "      <td>0.601977</td>\n",
       "      <td>0.594479</td>\n",
       "      <td>0.294934</td>\n",
       "      <td>0.279021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759502</td>\n",
       "      <td>0.593904</td>\n",
       "      <td>0.389199</td>\n",
       "      <td>0.728803</td>\n",
       "      <td>0.357802</td>\n",
       "      <td>0.601884</td>\n",
       "      <td>0.391146</td>\n",
       "      <td>0.647505</td>\n",
       "      <td>0.648642</td>\n",
       "      <td>0.265418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.254905</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.535820</td>\n",
       "      <td>0.447373</td>\n",
       "      <td>0.850517</td>\n",
       "      <td>0.417628</td>\n",
       "      <td>0.667081</td>\n",
       "      <td>0.582317</td>\n",
       "      <td>0.609142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410181</td>\n",
       "      <td>0.705125</td>\n",
       "      <td>0.474327</td>\n",
       "      <td>0.464437</td>\n",
       "      <td>0.222877</td>\n",
       "      <td>0.775034</td>\n",
       "      <td>0.218283</td>\n",
       "      <td>0.182324</td>\n",
       "      <td>0.687383</td>\n",
       "      <td>0.232704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.408357</td>\n",
       "      <td>0.539775</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.500064</td>\n",
       "      <td>0.325182</td>\n",
       "      <td>0.717406</td>\n",
       "      <td>0.424956</td>\n",
       "      <td>0.681060</td>\n",
       "      <td>0.671982</td>\n",
       "      <td>0.485690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727342</td>\n",
       "      <td>0.606357</td>\n",
       "      <td>0.447945</td>\n",
       "      <td>0.511046</td>\n",
       "      <td>0.337572</td>\n",
       "      <td>0.883857</td>\n",
       "      <td>0.558429</td>\n",
       "      <td>0.541227</td>\n",
       "      <td>0.339614</td>\n",
       "      <td>0.514331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.567520</td>\n",
       "      <td>0.586569</td>\n",
       "      <td>0.696941</td>\n",
       "      <td>0.588941</td>\n",
       "      <td>0.347404</td>\n",
       "      <td>0.481345</td>\n",
       "      <td>0.739656</td>\n",
       "      <td>0.235211</td>\n",
       "      <td>0.653272</td>\n",
       "      <td>0.441944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563075</td>\n",
       "      <td>0.611288</td>\n",
       "      <td>0.417291</td>\n",
       "      <td>0.504277</td>\n",
       "      <td>0.564603</td>\n",
       "      <td>0.521822</td>\n",
       "      <td>0.278146</td>\n",
       "      <td>0.219809</td>\n",
       "      <td>0.385580</td>\n",
       "      <td>0.440485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_0     var_1     var_2     var_3     var_4     var_5     var_6  \\\n",
       "0  0.535360  0.897837  0.628717  0.715833  0.548256  0.605894  0.574061   \n",
       "1  0.408005  0.641132  0.533050  0.395056  0.355501  0.573148  0.601977   \n",
       "2  0.254905  0.184314  0.465517  0.535820  0.447373  0.850517  0.417628   \n",
       "3  0.408357  0.539775  0.574667  0.500064  0.325182  0.717406  0.424956   \n",
       "4  0.567520  0.586569  0.696941  0.588941  0.347404  0.481345  0.739656   \n",
       "\n",
       "      var_7     var_8     var_9    ...      var_190   var_191   var_192  \\\n",
       "0  0.578182  0.611866  0.674016    ...     0.366928  0.749230  0.195180   \n",
       "1  0.594479  0.294934  0.279021    ...     0.759502  0.593904  0.389199   \n",
       "2  0.667081  0.582317  0.609142    ...     0.410181  0.705125  0.474327   \n",
       "3  0.681060  0.671982  0.485690    ...     0.727342  0.606357  0.447945   \n",
       "4  0.235211  0.653272  0.441944    ...     0.563075  0.611288  0.417291   \n",
       "\n",
       "    var_193   var_194   var_195   var_196   var_197   var_198   var_199  \n",
       "0  0.473444  0.260824  0.810571  0.570992  0.788006  0.463751  0.447387  \n",
       "1  0.728803  0.357802  0.601884  0.391146  0.647505  0.648642  0.265418  \n",
       "2  0.464437  0.222877  0.775034  0.218283  0.182324  0.687383  0.232704  \n",
       "3  0.511046  0.337572  0.883857  0.558429  0.541227  0.339614  0.514331  \n",
       "4  0.504277  0.564603  0.521822  0.278146  0.219809  0.385580  0.440485  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "clusters=8\n",
    "model = KMeans(n_clusters=clusters)\n",
    "\n",
    "labels_train=model.fit_predict(train)\n",
    "labels_test=model.predict(test)\n",
    "\n",
    "train['Cluster']=labels_train\n",
    "test['Cluster']=labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster nr: 0 test items: 25523 mean: 0.07895359848484848\n",
      "Cluster nr: 1 test items: 25167 mean: 0.08203751202308432\n",
      "Cluster nr: 2 test items: 24621 mean: 0.11018091232082329\n",
      "Cluster nr: 3 test items: 24296 mean: 0.16999272844792762\n",
      "Cluster nr: 4 test items: 25328 mean: 0.08954639740127587\n",
      "Cluster nr: 5 test items: 24727 mean: 0.09488668441003306\n",
      "Cluster nr: 6 test items: 24824 mean: 0.10958405756093617\n",
      "Cluster nr: 7 test items: 25514 mean: 0.07062068965517242\n",
      "-----Test dataset results-----\n",
      "Clusters homogeneity: 0.8997044827431163\n"
     ]
    }
   ],
   "source": [
    "mean_clusters=np.array(range(clusters))\n",
    "mean_train=labels_train\n",
    "mean_test=labels_test\n",
    "\n",
    "#how many rows in test\n",
    "rows=np.shape(test)[0]\n",
    "\n",
    "#score for measure accuracy of clasters\n",
    "score=0\n",
    "\n",
    "for cluster in range(clusters):\n",
    "    #compute the mean (HasDetection) of cluster\n",
    "    #mean =np.mean(Y_test.loc[test['Cluster'] == cluster])  #test measure\n",
    "    mean =np.mean(y_train.loc[train['Cluster'] == cluster]) # train measure\n",
    "    mean_clusters=np.where(mean_clusters==cluster, mean, mean_clusters)\n",
    "    #how many rows cluster has in test \n",
    "    count=test[test['Cluster']==cluster].count()[0]\n",
    "    #score for measure accuracy of clasters\n",
    "    score=score+abs(mean-0.5)*count/rows\n",
    "    print(\"Cluster nr:\",cluster,'test items:',count,'mean:',mean)\n",
    "    mean_train=np.where(mean_train==cluster, mean, mean_train)\n",
    "    mean_test=np.where(mean_test==cluster, mean, mean_test)\n",
    "\n",
    "print('-----Test dataset results-----')    \n",
    "print('Clusters homogeneity:',0.5+score)\n",
    "\n",
    "#train['Cluster_pred']=mean_train\n",
    "#test['Cluster_pred']=mean_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(200,), \n",
    "                    max_iter=5,\n",
    "                    learning_rate_init=.1,\n",
    "                    early_stopping=True,\n",
    "                    activation = 'relu',\n",
    "                    learning_rate = 'adaptive',\n",
    "                    solver='sgd', \n",
    "                    verbose=True,          \n",
    "                    random_state=32563246)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " ...]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=list(labels_test)\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.28209986\n",
      "Validation score: 0.916765\n",
      "Iteration 2, loss = 0.24806268\n",
      "Validation score: 0.916765\n",
      "Iteration 3, loss = 0.22873439\n",
      "Validation score: 0.916765\n",
      "Iteration 4, loss = 0.21961969\n",
      "Validation score: 0.917554\n",
      "Iteration 5, loss = 0.21517648\n",
      "Validation score: 0.919132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.29324591\n",
      "Validation score: 0.917869\n",
      "Iteration 2, loss = 0.25565975\n",
      "Validation score: 0.917869\n",
      "Iteration 3, loss = 0.24245969\n",
      "Validation score: 0.917869\n",
      "Iteration 4, loss = 0.22734310\n",
      "Validation score: 0.920272\n",
      "Iteration 5, loss = 0.21927787\n",
      "Validation score: 0.920272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.34923174\n",
      "Validation score: 0.888118\n",
      "Iteration 2, loss = 0.30919408\n",
      "Validation score: 0.882401\n",
      "Iteration 3, loss = 0.28241854\n",
      "Validation score: 0.901592\n",
      "Iteration 4, loss = 0.26717430\n",
      "Validation score: 0.897101\n",
      "Iteration 5, loss = 0.26044822\n",
      "Validation score: 0.896693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.45275447\n",
      "Validation score: 0.836430\n",
      "Iteration 2, loss = 0.40596197\n",
      "Validation score: 0.842488\n",
      "Iteration 3, loss = 0.38056862\n",
      "Validation score: 0.844911\n",
      "Iteration 4, loss = 0.35684082\n",
      "Validation score: 0.863086\n",
      "Iteration 5, loss = 0.34708169\n",
      "Validation score: 0.850565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.30579623\n",
      "Validation score: 0.896322\n",
      "Iteration 2, loss = 0.26950290\n",
      "Validation score: 0.896714\n",
      "Iteration 3, loss = 0.28678890\n",
      "Validation score: 0.896322\n",
      "Iteration 4, loss = 0.24983378\n",
      "Validation score: 0.896714\n",
      "Iteration 5, loss = 0.24395960\n",
      "Validation score: 0.899061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.32199591\n",
      "Validation score: 0.905645\n",
      "Iteration 2, loss = 0.28782620\n",
      "Validation score: 0.905645\n",
      "Iteration 3, loss = 0.26542133\n",
      "Validation score: 0.912500\n",
      "Iteration 4, loss = 0.25437345\n",
      "Validation score: 0.910081\n",
      "Iteration 5, loss = 0.24752078\n",
      "Validation score: 0.915323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.36025260\n",
      "Validation score: 0.886823\n",
      "Iteration 2, loss = 0.32285745\n",
      "Validation score: 0.886823\n",
      "Iteration 3, loss = 0.31440599\n",
      "Validation score: 0.886823\n",
      "Iteration 4, loss = 0.29602097\n",
      "Validation score: 0.888036\n",
      "Iteration 5, loss = 0.28875504\n",
      "Validation score: 0.888844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.27838812\n",
      "Validation score: 0.920410\n",
      "Iteration 2, loss = 0.23969289\n",
      "Validation score: 0.923956\n",
      "Iteration 3, loss = 0.23578305\n",
      "Validation score: 0.920410\n",
      "Iteration 4, loss = 0.22398694\n",
      "Validation score: 0.920410\n",
      "Iteration 5, loss = 0.22703222\n",
      "Validation score: 0.920410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "for cluster in range(clusters):\n",
    "    #compute the mean (HasDetection) of cluster\n",
    "    #mean =np.mean(Y_test.loc[test['Cluster'] == cluster])  #test measure\n",
    "    y=y_train.loc[train['Cluster'] == cluster] # y train \n",
    "    X_train=train.loc[train['Cluster'] == cluster] # train\n",
    "    X_test=test.loc[test['Cluster'] == cluster] # train measure\n",
    "    \n",
    "    model.fit(X_train, y)\n",
    "    pred=list(model.predict(X_test))\n",
    "    for val in range(np.shape(pred_test)[0]):\n",
    "        if test['Cluster'][val] == cluster:\n",
    "            pred_test[val]=pred.pop(0)\n",
    "   \n",
    "    \n",
    "\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "   \n",
    "submission['target'] = pred_test\n",
    "submission.to_csv('./output/submission.csv',index=False)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
